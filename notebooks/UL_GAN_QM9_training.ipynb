{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_folder = '../codes'\n",
    "import sys\n",
    "sys.path.append(code_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import packages\n",
    "import numpy as np\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from rdkit import RDLogger    \n",
    "from torch_geometric.data import Data\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "from util_gnn import draw_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miniconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "### Load data\n",
    "batch_size = 64\n",
    "mol_data = torch.load('qm9_smiles_noar.pt')\n",
    "data_list = torch.load('qm9_data_noar.pt')\n",
    "data_loader = DataLoader(data_list, batch_size=batch_size, shuffle=True, follow_batch=['edge_index', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn_model_sim_summ_2 import *\n",
    "from ugcn_model_summ_2 import pre_GCNModel_edge_3eos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if(torch.cuda.is_available()) else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build discriminators\n",
    "\n",
    "gcn_model = pre_GCNModel_edge_3eos(in_dim=10, \\\n",
    "                                   hidden_dim=128, \\\n",
    "                                   edge_dim=3, \\\n",
    "                                   edge_hidden_dim=32, \\\n",
    "                                   lin_hidden_dim=128, \\\n",
    "                                   out_hidden_dim=256, \\\n",
    "                                   device=device, \\\n",
    "                                    check_batch=None, \n",
    "                                    useBN=True, \\\n",
    "                                    droprate=0.3, \n",
    "                                    pool_method='trivial', \\\n",
    "                                    add_edge_link=False, \n",
    "                                    add_conv_link=True, \\\n",
    "                                    outBN=False, out_drop=0.3, \n",
    "                                    out_divide=4.0, \n",
    "                                    add_edge_agg=False, \n",
    "                                    real_trivial=False, \n",
    "                                    final_layers=2, \n",
    "                                    add_trivial_feature=False).to(device)\n",
    "\n",
    "added_d = pre_GCNModel_edge_3eos(in_dim=10, \\\n",
    "                                   hidden_dim=128, \\\n",
    "                                   edge_dim=3, \\\n",
    "                                   edge_hidden_dim=32, \\\n",
    "                                   lin_hidden_dim=128, \\\n",
    "                                   out_hidden_dim=256, \\\n",
    "                                   device=device, \\\n",
    "                                    check_batch=None, \n",
    "                                    useBN=False, \\\n",
    "                                    droprate=0.3, \n",
    "                                    pool_method='trivial', \\\n",
    "                                    add_edge_link=False, \\\n",
    "                                    add_conv_link=False, \\\n",
    "                                    outBN=False, out_drop=0.3, \n",
    "                                    out_divide=4.0, \n",
    "                                    add_edge_agg=False, \n",
    "                                    real_trivial=True, \n",
    "                                    final_layers=2, \n",
    "                                    add_trivial_feature=True).to(device)\n",
    "added_d.e1_ind = 0.0 # Not consider the mean of edges, just the sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build generator\n",
    "\n",
    "generator = UnpoolGeneratorQ(in_dim=256, \\\n",
    "                            edge_dim=3, \n",
    "                            node_dim=10, \n",
    "                            node_hidden_dim=[128, 128, 128, 64, 64], \n",
    "                            edge_hidden_dim=64, \\\n",
    "                            use_x_bn=True, \n",
    "                            use_e_bn=True, \n",
    "                            unpool_bn=True, \n",
    "                            link_bn=False, \n",
    "                            attr_bn=True, \n",
    "                            skip_z=True, \n",
    "                            skip_zdim=None, \n",
    "                            conv_type='nn', \n",
    "                            device=device, \n",
    "                            last_act='leaky', \n",
    "                            link_act='leaky', \\\n",
    "                            unpool_para=dict(add_perference=True, roll_bn=False, roll_simple=True, \\\n",
    "                                            add_additional_link=True), \\\n",
    "                             without_aroma=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import GANTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = GANTrainer(d=gcn_model, g=generator, \\\n",
    "                   rand_dim=256, train_folder='ULGAN_QM9', \\\n",
    "                   tot_epoch_num=200, eval_iter_num=1000, \\\n",
    "                   batch_size=64, \\\n",
    "                   device=device, d_add=added_d, \\\n",
    "                   learning_rate_g=2e-4, learning_rate_d=1e-4, \\\n",
    "                   lambda_g=10.0, \\\n",
    "                   max_train_G=2, \\\n",
    "                   tresh_add_trainG=0.2, \\\n",
    "                   use_loss='wgan', \\\n",
    "                   g_out_prob=True, \\\n",
    "                   lambda_rl=5e-3, lambda_nonodes = 0., \n",
    "                   lambda_noedges = 0., \\\n",
    "                   qm9=True, \\\n",
    "                   without_ar=True, \\\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miniconda3/envs/gnn/lib/python3.9/site-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/miniconda3/envs/gnn/lib/python3.9/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/200][0/2079]\tG Loss: -0.0002;D Loss: -0.0139; GP: 19.4810\n",
      "now, we train G 1 times with (prob fake = 0.000, prob real = 0.015)\n",
      "Mean x/edge attr:  tensor([0.2807, 0.2266, 0.2599, 0.2328, 0.3410, 0.3306, 0.3285, 0.3139, 0.3326,\n",
      "        0.3534], grad_fn=<MeanBackward1>) tensor([0.3252, 0.3481, 0.3267], grad_fn=<MeanBackward1>) tensor(19.7500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 7.515625 tensor([6., 7., 8., 8., 8., 7., 6., 6., 9., 6., 7., 9., 8., 7., 6., 6., 7., 7.,\n",
      "        9., 8., 6., 9., 6., 9., 8., 7., 9., 9., 9., 9., 7., 6., 7., 8., 7., 9.,\n",
      "        8., 6., 7., 9., 9., 9., 7., 8., 8., 9., 6., 6., 8., 9., 8., 6., 6., 8.,\n",
      "        8., 7., 9., 7., 7., 6., 9., 7., 8., 6.])\n",
      "Sample prob: -15.612592697143555\n",
      "Validation, uniqueness, novelty:  (0.001, 1.0, 1.0)\n",
      "[1/200][100/2079]\tG Loss: 0.0488;D Loss: -0.2715; GP: 2.4253\n",
      "now, we train G 2 times with (prob fake = -0.049, prob real = 0.220)\n",
      "Mean x/edge attr:  tensor([0.6411, 0.1152, 0.1094, 0.1344, 0.7812, 0.1094, 0.1094, 0.7812, 0.0998,\n",
      "        0.1190], grad_fn=<MeanBackward1>) tensor([0.6460, 0.1725, 0.1815], grad_fn=<MeanBackward1>) tensor(36.5000, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.140625 tensor([9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 8., 7., 8., 7., 6., 9., 9., 9.,\n",
      "        9., 8., 7., 7., 9., 8., 7., 8., 9., 6., 9., 8., 7., 7., 7., 8., 9., 9.,\n",
      "        8., 9., 9., 8., 8., 9., 9., 7., 9., 6., 9., 8., 7., 9., 8., 9., 9., 6.,\n",
      "        8., 8., 8., 7., 9., 7., 8., 8., 8., 9.])\n",
      "Sample prob: -16.15403175354004\n",
      "[1/200][200/2079]\tG Loss: -0.0262;D Loss: -0.2151; GP: 1.4562\n",
      "now, we train G 2 times with (prob fake = 0.026, prob real = 0.237)\n",
      "Mean x/edge attr:  tensor([0.8937, 0.0368, 0.0286, 0.0409, 0.9571, 0.0123, 0.0307, 0.9366, 0.0286,\n",
      "        0.0348], grad_fn=<MeanBackward1>) tensor([0.7901, 0.1171, 0.0928], grad_fn=<MeanBackward1>) tensor(21.2188, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 7.640625 tensor([9., 6., 9., 9., 7., 7., 9., 9., 8., 9., 6., 7., 8., 6., 9., 7., 7., 8.,\n",
      "        9., 7., 7., 8., 7., 6., 6., 7., 7., 7., 9., 7., 6., 9., 9., 7., 9., 9.,\n",
      "        7., 8., 9., 7., 7., 8., 9., 7., 8., 6., 9., 9., 8., 6., 8., 6., 9., 9.,\n",
      "        6., 6., 8., 9., 7., 6., 6., 9., 8., 8.])\n",
      "Sample prob: -13.937480926513672\n",
      "Validation, uniqueness, novelty:  (0.157, 0.8980891719745223, 0.8156028368794326)\n",
      "[1/200][300/2079]\tG Loss: -0.3065;D Loss: -0.2178; GP: 0.7734\n",
      "now, we train G 2 times with (prob fake = 0.306, prob real = 0.522)\n",
      "Mean x/edge attr:  tensor([0.6618, 0.3008, 0.0187, 0.0187, 0.9959, 0.0021, 0.0021, 0.8174, 0.0871,\n",
      "        0.0954], grad_fn=<MeanBackward1>) tensor([0.9283, 0.0343, 0.0374], grad_fn=<MeanBackward1>) tensor(15.0312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 7.53125 tensor([7., 6., 8., 7., 6., 6., 6., 7., 9., 7., 9., 8., 7., 8., 6., 9., 8., 7.,\n",
      "        9., 9., 8., 8., 7., 7., 9., 9., 7., 7., 9., 6., 9., 9., 6., 9., 8., 8.,\n",
      "        9., 9., 9., 9., 8., 9., 7., 6., 8., 6., 6., 7., 8., 6., 9., 6., 7., 9.,\n",
      "        7., 7., 8., 6., 7., 6., 7., 7., 6., 8.])\n",
      "Sample prob: -9.077473640441895\n",
      "[1/200][400/2079]\tG Loss: -0.3447;D Loss: -0.2724; GP: 0.5557\n",
      "now, we train G 2 times with (prob fake = 0.345, prob real = 0.590)\n",
      "Mean x/edge attr:  tensor([0.8303, 0.1119, 0.0361, 0.0217, 0.9982, 0.0000, 0.0018, 0.7292, 0.0776,\n",
      "        0.1931], grad_fn=<MeanBackward1>) tensor([0.9663, 0.0208, 0.0129], grad_fn=<MeanBackward1>) tensor(15.7500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.65625 tensor([9., 9., 9., 9., 9., 6., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 7., 9., 8., 9., 9., 8.,\n",
      "        9., 9., 7., 6., 7., 9., 6., 9., 9., 9.])\n",
      "Sample prob: -2.5723319053649902\n",
      "Validation, uniqueness, novelty:  (0.015, 0.9333333333333333, 0.7142857142857143)\n",
      "[1/200][500/2079]\tG Loss: -0.5461;D Loss: -0.2687; GP: 0.6615\n",
      "now, we train G 2 times with (prob fake = 0.546, prob real = 0.804)\n",
      "Mean x/edge attr:  tensor([0.2880, 0.0555, 0.6225, 0.0340, 0.9911, 0.0036, 0.0054, 0.9177, 0.0304,\n",
      "        0.0519], grad_fn=<MeanBackward1>) tensor([0.8093, 0.1440, 0.0467], grad_fn=<MeanBackward1>) tensor(16.0625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.734375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 8., 9., 9., 9.,\n",
      "        9., 9., 9., 8., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 7., 9.,\n",
      "        9., 8., 9., 7., 9., 6., 8., 9., 9., 8.])\n",
      "Sample prob: -2.788334369659424\n",
      "[1/200][600/2079]\tG Loss: -0.4990;D Loss: -0.3892; GP: 0.5480\n",
      "now, we train G 2 times with (prob fake = 0.499, prob real = 0.859)\n",
      "Mean x/edge attr:  tensor([0.8270, 0.0324, 0.1243, 0.0162, 0.9892, 0.0054, 0.0054, 0.7351, 0.0559,\n",
      "        0.2090], grad_fn=<MeanBackward1>) tensor([0.6660, 0.1689, 0.1650], grad_fn=<MeanBackward1>) tensor(16., grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.671875 tensor([8., 8., 9., 9., 7., 9., 8., 9., 9., 9., 8., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        7., 9., 9., 8., 9., 9., 9., 7., 7., 8., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6., 8.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.5426571369171143\n",
      "Validation, uniqueness, novelty:  (0.002, 1.0, 0.0)\n",
      "[1/200][700/2079]\tG Loss: -0.1543;D Loss: -0.5528; GP: 0.9305\n",
      "now, we train G 2 times with (prob fake = 0.154, prob real = 0.703)\n",
      "Mean x/edge attr:  tensor([0.6596, 0.0213, 0.3014, 0.0177, 0.9787, 0.0142, 0.0071, 0.6755, 0.0993,\n",
      "        0.2252], grad_fn=<MeanBackward1>) tensor([0.7407, 0.2447, 0.0145], grad_fn=<MeanBackward1>) tensor(19.3438, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.8125 tensor([9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 9., 7., 8., 9., 9., 9., 9., 7., 9., 9., 9., 7., 9.,\n",
      "        9., 9., 9., 9., 8., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.3588178157806396\n",
      "[1/200][800/2079]\tG Loss: -0.0181;D Loss: -0.6831; GP: 0.5942\n",
      "now, we train G 2 times with (prob fake = 0.018, prob real = 0.679)\n",
      "Mean x/edge attr:  tensor([0.3077, 0.6573, 0.0280, 0.0070, 0.9703, 0.0052, 0.0245, 0.9038, 0.0385,\n",
      "        0.0577], grad_fn=<MeanBackward1>) tensor([0.7026, 0.2113, 0.0861], grad_fn=<MeanBackward1>) tensor(17.9688, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.9375 tensor([7., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -1.4794931411743164\n",
      "Validation, uniqueness, novelty:  (0.0, 0, 0)\n",
      "[1/200][900/2079]\tG Loss: 0.1089;D Loss: -0.6921; GP: 0.3851\n",
      "now, we train G 2 times with (prob fake = -0.109, prob real = 0.614)\n",
      "Mean x/edge attr:  tensor([0.7384, 0.1103, 0.1512, 0.0000, 0.9822, 0.0125, 0.0053, 0.8345, 0.0943,\n",
      "        0.0712], grad_fn=<MeanBackward1>) tensor([0.9964, 0.0036, 0.0000], grad_fn=<MeanBackward1>) tensor(17.4375, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.78125 tensor([9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7.,\n",
      "        7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 7., 8., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 7., 9., 9., 9., 9., 7., 9., 9.])\n",
      "Sample prob: -1.8134502172470093\n",
      "[1/200][1000/2079]\tG Loss: 0.1225;D Loss: -0.9283; GP: 0.6503\n",
      "now, we train G 2 times with (prob fake = -0.123, prob real = 0.773)\n",
      "Mean x/edge attr:  tensor([0.7301, 0.0978, 0.1721, 0.0000, 0.9964, 0.0018, 0.0018, 0.8170, 0.0743,\n",
      "        0.1087], grad_fn=<MeanBackward1>) tensor([0.7577, 0.1533, 0.0889], grad_fn=<MeanBackward1>) tensor(19.1562, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.625 tensor([9., 9., 9., 8., 9., 8., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 7., 9., 9., 9., 9., 8., 9., 9., 7., 9., 8., 9.,\n",
      "        7., 7., 7., 9., 9., 9., 9., 9., 7., 9., 9., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 7., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.6548521518707275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation, uniqueness, novelty:  (0.007, 0.8571428571428571, 1.0)\n",
      "[1/200][1100/2079]\tG Loss: 0.0969;D Loss: -0.8880; GP: 0.4370\n",
      "now, we train G 2 times with (prob fake = -0.097, prob real = 0.888)\n",
      "Mean x/edge attr:  tensor([0.7000, 0.1462, 0.1538, 0.0000, 0.9577, 0.0327, 0.0096, 0.7885, 0.0615,\n",
      "        0.1500], grad_fn=<MeanBackward1>) tensor([0.8484, 0.0901, 0.0615], grad_fn=<MeanBackward1>) tensor(18.0312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.125 tensor([7., 7., 9., 9., 7., 8., 6., 7., 8., 9., 7., 8., 8., 9., 7., 9., 6., 7.,\n",
      "        7., 9., 7., 9., 8., 9., 8., 9., 7., 9., 9., 9., 7., 8., 7., 8., 7., 7.,\n",
      "        9., 7., 9., 6., 9., 9., 9., 9., 8., 8., 7., 9., 9., 9., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 9., 9., 7., 9., 8., 8., 9.])\n",
      "Sample prob: -4.5749711990356445\n",
      "[1/200][1200/2079]\tG Loss: -0.2387;D Loss: -0.5814; GP: 0.3770\n",
      "now, we train G 2 times with (prob fake = 0.239, prob real = 0.870)\n",
      "Mean x/edge attr:  tensor([0.7098, 0.1314, 0.1588, 0.0000, 0.9588, 0.0353, 0.0059, 0.8196, 0.0490,\n",
      "        0.1314], grad_fn=<MeanBackward1>) tensor([0.8688, 0.1280, 0.0033], grad_fn=<MeanBackward1>) tensor(14.4062, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 7.96875 tensor([9., 6., 7., 9., 9., 9., 9., 7., 7., 7., 7., 9., 7., 9., 7., 7., 7., 6.,\n",
      "        7., 9., 9., 9., 9., 9., 6., 9., 7., 9., 7., 8., 9., 6., 9., 9., 7., 9.,\n",
      "        9., 9., 9., 9., 6., 9., 7., 7., 7., 8., 7., 9., 9., 7., 7., 7., 7., 9.,\n",
      "        9., 9., 7., 6., 9., 9., 9., 7., 9., 9.])\n",
      "Sample prob: -6.596336364746094\n",
      "Validation, uniqueness, novelty:  (0.732, 0.9057377049180327, 0.9155354449472096)\n",
      "[1/200][1300/2079]\tG Loss: -0.3342;D Loss: -0.4705; GP: 0.2369\n",
      "now, we train G 2 times with (prob fake = 0.334, prob real = 0.733)\n",
      "Mean x/edge attr:  tensor([0.7564, 0.1081, 0.1355, 0.0000, 0.9817, 0.0183, 0.0000, 0.7802, 0.1026,\n",
      "        0.1172], grad_fn=<MeanBackward1>) tensor([0.8949, 0.0646, 0.0404], grad_fn=<MeanBackward1>) tensor(15.4688, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.53125 tensor([9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 7., 9., 9., 9.,\n",
      "        9., 7., 9., 9., 7., 9., 9., 9., 9., 9., 7., 9., 7., 9., 9., 7., 9., 7.,\n",
      "        9., 9., 7., 9., 9., 8., 9., 9., 7., 7., 9., 9., 9., 9., 7., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 7., 7., 9., 9., 9.])\n",
      "Sample prob: -6.434516906738281\n",
      "[1/200][1400/2079]\tG Loss: -0.1470;D Loss: -0.4313; GP: 0.1933\n",
      "now, we train G 2 times with (prob fake = 0.147, prob real = 0.640)\n",
      "Mean x/edge attr:  tensor([0.6589, 0.1429, 0.1982, 0.0000, 0.9429, 0.0482, 0.0089, 0.7875, 0.0607,\n",
      "        0.1518], grad_fn=<MeanBackward1>) tensor([0.9297, 0.0527, 0.0176], grad_fn=<MeanBackward1>) tensor(16., grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.75 tensor([9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 7., 9., 8., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 7., 9., 9., 9., 9., 9., 9., 7., 7., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 7., 9.,\n",
      "        9., 9., 9., 9., 7., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -6.217613220214844\n",
      "Validation, uniqueness, novelty:  (0.926, 0.9643628509719222, 0.9204927211646137)\n",
      "[1/200][1500/2079]\tG Loss: -0.2398;D Loss: -0.4637; GP: 0.1435\n",
      "now, we train G 2 times with (prob fake = 0.240, prob real = 0.657)\n",
      "Mean x/edge attr:  tensor([0.7456, 0.1307, 0.1237, 0.0000, 0.9965, 0.0017, 0.0017, 0.7805, 0.0488,\n",
      "        0.1707], grad_fn=<MeanBackward1>) tensor([0.8746, 0.1243, 0.0012], grad_fn=<MeanBackward1>) tensor(26.4062, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.96875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -13.136297225952148\n",
      "[1/200][1600/2079]\tG Loss: 0.3254;D Loss: -0.8936; GP: 0.2426\n",
      "now, we train G 2 times with (prob fake = -0.325, prob real = 0.533)\n",
      "Mean x/edge attr:  tensor([0.6981, 0.1396, 0.1623, 0.0000, 0.9581, 0.0349, 0.0070, 0.8185, 0.0681,\n",
      "        0.1134], grad_fn=<MeanBackward1>) tensor([0.8621, 0.1121, 0.0257], grad_fn=<MeanBackward1>) tensor(20.0625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.953125 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -8.216005325317383\n",
      "Validation, uniqueness, novelty:  (0.303, 0.8547854785478548, 0.8957528957528957)\n",
      "[1/200][1700/2079]\tG Loss: 0.3818;D Loss: -0.7876; GP: 0.1798\n",
      "now, we train G 2 times with (prob fake = -0.382, prob real = 0.541)\n",
      "Mean x/edge attr:  tensor([0.7268, 0.0788, 0.1926, 0.0018, 0.9877, 0.0088, 0.0035, 0.7601, 0.1068,\n",
      "        0.1331], grad_fn=<MeanBackward1>) tensor([0.8616, 0.0870, 0.0514], grad_fn=<MeanBackward1>) tensor(19.7500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.921875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9.,\n",
      "        9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -8.277153968811035\n",
      "[1/200][1800/2079]\tG Loss: 0.1266;D Loss: -0.5315; GP: 0.1468\n",
      "now, we train G 2 times with (prob fake = -0.127, prob real = 0.502)\n",
      "Mean x/edge attr:  tensor([0.7164, 0.0945, 0.1891, 0.0000, 0.9909, 0.0091, 0.0000, 0.8127, 0.0782,\n",
      "        0.1091], grad_fn=<MeanBackward1>) tensor([0.9049, 0.0716, 0.0236], grad_fn=<MeanBackward1>) tensor(17.2500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.59375 tensor([9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 7., 7., 9., 9., 9., 9.,\n",
      "        9., 7., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 7., 7., 9., 9., 9., 9., 7., 9., 7., 9., 9., 7., 9., 9., 9., 9.,\n",
      "        7., 9., 9., 9., 9., 9., 7., 7., 9., 9.])\n",
      "Sample prob: -8.170495986938477\n",
      "Validation, uniqueness, novelty:  (0.743, 0.9421265141318977, 0.8871428571428571)\n",
      "[1/200][1900/2079]\tG Loss: -0.0745;D Loss: -0.5745; GP: 0.1476\n",
      "now, we train G 2 times with (prob fake = 0.074, prob real = 0.522)\n",
      "Mean x/edge attr:  tensor([0.7434, 0.1037, 0.1529, 0.0000, 0.9666, 0.0299, 0.0035, 0.8207, 0.0633,\n",
      "        0.1160], grad_fn=<MeanBackward1>) tensor([0.8918, 0.0746, 0.0336], grad_fn=<MeanBackward1>) tensor(16.7500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.890625 tensor([9., 9., 9., 8., 9., 9., 7., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -7.254340648651123\n",
      "[1/200][2000/2079]\tG Loss: 0.2018;D Loss: -1.1067; GP: 0.8560\n",
      "now, we train G 2 times with (prob fake = -0.202, prob real = 0.654)\n",
      "Mean x/edge attr:  tensor([0.7527, 0.0961, 0.1512, 0.0000, 0.9662, 0.0231, 0.0107, 0.7954, 0.0516,\n",
      "        0.1530], grad_fn=<MeanBackward1>) tensor([0.8740, 0.0759, 0.0501], grad_fn=<MeanBackward1>) tensor(19.9688, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.78125 tensor([7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 7., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 7., 9., 9., 9.])\n",
      "Sample prob: -7.56417179107666\n",
      "Validation, uniqueness, novelty:  (0.304, 0.9967105263157895, 0.9570957095709571)\n",
      "less than 64\n",
      "[2/200][22/2079]\tG Loss: 0.1056;D Loss: -0.7594; GP: 0.2298\n",
      "now, we train G 2 times with (prob fake = -0.106, prob real = 0.482)\n",
      "Mean x/edge attr:  tensor([0.7138, 0.1325, 0.1537, 0.0000, 0.9541, 0.0424, 0.0035, 0.7827, 0.0707,\n",
      "        0.1466], grad_fn=<MeanBackward1>) tensor([0.8291, 0.0988, 0.0721], grad_fn=<MeanBackward1>) tensor(15.8125, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.84375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        7., 9., 9., 8., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 7., 9., 9., 9.])\n",
      "Sample prob: -6.432637691497803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/200][122/2079]\tG Loss: -0.0817;D Loss: -0.3048; GP: 2.9606\n",
      "now, we train G 2 times with (prob fake = 0.082, prob real = 0.171)\n",
      "Mean x/edge attr:  tensor([0.7339, 0.1054, 0.1607, 0.0000, 0.9911, 0.0036, 0.0054, 0.7589, 0.1750,\n",
      "        0.0661], grad_fn=<MeanBackward1>) tensor([0.8424, 0.1263, 0.0314], grad_fn=<MeanBackward1>) tensor(18.4375, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.75 tensor([7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 7., 7., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 6., 9., 9., 9.])\n",
      "Sample prob: -7.388788223266602\n",
      "Validation, uniqueness, novelty:  (0.83, 0.8566265060240964, 0.9254571026722925)\n",
      "[2/200][222/2079]\tG Loss: 0.2517;D Loss: -0.6899; GP: 0.3718\n",
      "now, we train G 2 times with (prob fake = -0.252, prob real = 0.360)\n",
      "Mean x/edge attr:  tensor([0.6972, 0.1074, 0.1954, 0.0000, 0.9771, 0.0176, 0.0053, 0.7729, 0.0739,\n",
      "        0.1532], grad_fn=<MeanBackward1>) tensor([0.8354, 0.1487, 0.0158], grad_fn=<MeanBackward1>) tensor(19.7500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.875 tensor([9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 8., 9., 9., 9., 8., 8., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -8.194704055786133\n",
      "[2/200][322/2079]\tG Loss: 0.5145;D Loss: -0.9502; GP: 0.2310\n",
      "now, we train G 2 times with (prob fake = -0.514, prob real = 0.370)\n",
      "Mean x/edge attr:  tensor([0.7067, 0.1714, 0.1219, 0.0000, 0.9823, 0.0159, 0.0018, 0.8004, 0.0565,\n",
      "        0.1431], grad_fn=<MeanBackward1>) tensor([0.8287, 0.1372, 0.0341], grad_fn=<MeanBackward1>) tensor(19.2500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.84375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 7.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 7.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.510187149047852\n",
      "Validation, uniqueness, novelty:  (0.491, 0.4786150712830957, 0.9744680851063829)\n",
      "[2/200][422/2079]\tG Loss: 0.1633;D Loss: -0.7402; GP: 0.2353\n",
      "now, we train G 2 times with (prob fake = -0.163, prob real = 0.654)\n",
      "Mean x/edge attr:  tensor([0.7444, 0.1063, 0.1493, 0.0000, 0.9515, 0.0429, 0.0056, 0.7649, 0.0877,\n",
      "        0.1474], grad_fn=<MeanBackward1>) tensor([0.8821, 0.1127, 0.0052], grad_fn=<MeanBackward1>) tensor(18.0312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.375 tensor([9., 9., 9., 7., 9., 9., 7., 7., 9., 7., 9., 9., 9., 7., 7., 9., 7., 9.,\n",
      "        9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 7., 9., 7., 7., 7.,\n",
      "        9., 7., 9., 9., 9., 9., 9., 9., 9., 7., 9., 7., 9., 7., 9., 7., 9., 7.,\n",
      "        7., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.125071048736572\n",
      "[2/200][522/2079]\tG Loss: -0.3110;D Loss: -0.4603; GP: 0.1618\n",
      "now, we train G 2 times with (prob fake = 0.311, prob real = 0.730)\n",
      "Mean x/edge attr:  tensor([0.8027, 0.0716, 0.1257, 0.0000, 0.9729, 0.0155, 0.0116, 0.7640, 0.0774,\n",
      "        0.1586], grad_fn=<MeanBackward1>) tensor([0.8927, 0.0784, 0.0290], grad_fn=<MeanBackward1>) tensor(18.3438, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.078125 tensor([7., 9., 7., 9., 7., 7., 9., 9., 7., 7., 7., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        7., 7., 7., 7., 9., 7., 7., 9., 9., 7., 9., 9., 9., 9., 7., 9., 9., 9.,\n",
      "        9., 7., 7., 7., 9., 7., 9., 7., 9., 9., 7., 7., 7., 7., 7., 8., 9., 9.,\n",
      "        9., 9., 9., 9., 7., 7., 9., 9., 7., 7.])\n",
      "Sample prob: -4.52895450592041\n",
      "Validation, uniqueness, novelty:  (0.811, 0.5006165228113441, 0.9458128078817734)\n",
      "[2/200][622/2079]\tG Loss: -0.2798;D Loss: -0.5398; GP: 0.1637\n",
      "now, we train G 2 times with (prob fake = 0.280, prob real = 0.819)\n",
      "Mean x/edge attr:  tensor([0.7062, 0.1223, 0.1715, 0.0000, 0.9580, 0.0401, 0.0018, 0.7263, 0.0931,\n",
      "        0.1807], grad_fn=<MeanBackward1>) tensor([0.8802, 0.0781, 0.0417], grad_fn=<MeanBackward1>) tensor(18., grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.5625 tensor([9., 9., 9., 9., 9., 7., 9., 9., 7., 7., 9., 9., 7., 7., 9., 9., 9., 9.,\n",
      "        9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7.,\n",
      "        9., 9., 9., 7., 7., 9., 9., 9., 8., 9., 7., 9., 9., 9., 9., 9., 7., 7.,\n",
      "        9., 8., 9., 9., 9., 9., 9., 9., 9., 7.])\n",
      "Sample prob: -7.432488441467285\n",
      "[2/200][722/2079]\tG Loss: -0.0767;D Loss: -0.8674; GP: 0.2489\n",
      "now, we train G 2 times with (prob fake = 0.077, prob real = 0.986)\n",
      "Mean x/edge attr:  tensor([0.7105, 0.1000, 0.1895, 0.0000, 0.9860, 0.0070, 0.0070, 0.7930, 0.0719,\n",
      "        0.1351], grad_fn=<MeanBackward1>) tensor([0.8558, 0.1351, 0.0091], grad_fn=<MeanBackward1>) tensor(18.9688, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.90625 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 7., 9., 9., 9.,\n",
      "        9., 7., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.805727958679199\n",
      "Validation, uniqueness, novelty:  (0.491, 0.7780040733197556, 0.887434554973822)\n",
      "[2/200][822/2079]\tG Loss: 0.0838;D Loss: -1.1297; GP: 0.2736\n",
      "now, we train G 2 times with (prob fake = -0.084, prob real = 0.988)\n",
      "Mean x/edge attr:  tensor([0.8081, 0.0387, 0.1532, 0.0000, 0.9736, 0.0211, 0.0053, 0.6884, 0.0968,\n",
      "        0.2148], grad_fn=<MeanBackward1>) tensor([0.9402, 0.0279, 0.0320], grad_fn=<MeanBackward1>) tensor(19.0625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.875 tensor([9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 7., 9., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.3041000366210938\n",
      "[2/200][922/2079]\tG Loss: 0.2879;D Loss: -1.2520; GP: 0.4783\n",
      "now, we train G 2 times with (prob fake = -0.288, prob real = 0.956)\n",
      "Mean x/edge attr:  tensor([0.7298, 0.0860, 0.1842, 0.0000, 0.9333, 0.0509, 0.0158, 0.7526, 0.1035,\n",
      "        0.1439], grad_fn=<MeanBackward1>) tensor([0.8961, 0.0771, 0.0268], grad_fn=<MeanBackward1>) tensor(18.6562, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.90625 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 7., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.732215404510498\n",
      "Validation, uniqueness, novelty:  (0.157, 0.5923566878980892, 0.946236559139785)\n",
      "[2/200][1022/2079]\tG Loss: 0.2743;D Loss: -1.0673; GP: 0.2234\n",
      "now, we train G 2 times with (prob fake = -0.274, prob real = 0.722)\n",
      "Mean x/edge attr:  tensor([0.6514, 0.2165, 0.1320, 0.0000, 0.9683, 0.0141, 0.0176, 0.8063, 0.0704,\n",
      "        0.1232], grad_fn=<MeanBackward1>) tensor([0.8468, 0.1228, 0.0305], grad_fn=<MeanBackward1>) tensor(17.4375, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 7., 9., 9., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 8., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.418924331665039\n",
      "[2/200][1122/2079]\tG Loss: 0.4012;D Loss: -1.1762; GP: 0.1901\n",
      "now, we train G 2 times with (prob fake = -0.401, prob real = 0.827)\n",
      "Mean x/edge attr:  tensor([0.6962, 0.1245, 0.1792, 0.0000, 0.9491, 0.0208, 0.0302, 0.8245, 0.0509,\n",
      "        0.1245], grad_fn=<MeanBackward1>) tensor([0.8444, 0.0973, 0.0584], grad_fn=<MeanBackward1>) tensor(16.0625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.28125 tensor([9., 9., 7., 7., 7., 9., 7., 7., 9., 9., 9., 7., 9., 9., 9., 7., 7., 7.,\n",
      "        7., 9., 7., 9., 9., 9., 7., 9., 9., 9., 7., 9., 7., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 9., 9., 7., 9., 7., 9., 9., 9., 7., 7., 9., 9., 9., 9., 7., 9.,\n",
      "        7., 9., 9., 9., 9., 9., 9., 9., 7., 7.])\n",
      "Sample prob: -4.940645694732666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation, uniqueness, novelty:  (0.506, 0.8478260869565217, 0.8601398601398601)\n",
      "[2/200][1222/2079]\tG Loss: 0.1203;D Loss: -0.9433; GP: 0.1768\n",
      "now, we train G 2 times with (prob fake = -0.120, prob real = 0.821)\n",
      "Mean x/edge attr:  tensor([0.7148, 0.1604, 0.1248, 0.0000, 0.9590, 0.0178, 0.0232, 0.7879, 0.0713,\n",
      "        0.1408], grad_fn=<MeanBackward1>) tensor([0.8546, 0.1420, 0.0034], grad_fn=<MeanBackward1>) tensor(18.3750, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.765625 tensor([9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 7., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 7., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 7., 9., 9., 7., 9.])\n",
      "Sample prob: -5.210018157958984\n",
      "[2/200][1322/2079]\tG Loss: 0.2516;D Loss: -0.7915; GP: 0.2046\n",
      "now, we train G 2 times with (prob fake = -0.252, prob real = 0.524)\n",
      "Mean x/edge attr:  tensor([0.7325, 0.1167, 0.1508, 0.0000, 0.9497, 0.0233, 0.0269, 0.7917, 0.0754,\n",
      "        0.1329], grad_fn=<MeanBackward1>) tensor([0.9343, 0.0033, 0.0624], grad_fn=<MeanBackward1>) tensor(19.0312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.703125 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 7., 9., 9., 7., 9., 9., 9., 9.,\n",
      "        9., 7., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 7., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 7., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.78879976272583\n",
      "Validation, uniqueness, novelty:  (0.789, 0.49302915082382764, 0.9640102827763496)\n",
      "[2/200][1422/2079]\tG Loss: 0.1941;D Loss: -0.7280; GP: 0.1180\n",
      "now, we train G 2 times with (prob fake = -0.194, prob real = 0.448)\n",
      "Mean x/edge attr:  tensor([0.7133, 0.1503, 0.1364, 0.0000, 0.9703, 0.0297, 0.0000, 0.7710, 0.1101,\n",
      "        0.1189], grad_fn=<MeanBackward1>) tensor([0.8213, 0.1275, 0.0512], grad_fn=<MeanBackward1>) tensor(18.6250, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.9375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -7.503390312194824\n",
      "[2/200][1522/2079]\tG Loss: 0.1063;D Loss: -0.5219; GP: 0.1335\n",
      "now, we train G 2 times with (prob fake = -0.106, prob real = 0.310)\n",
      "Mean x/edge attr:  tensor([0.7289, 0.1039, 0.1673, 0.0000, 0.9683, 0.0141, 0.0176, 0.7729, 0.0722,\n",
      "        0.1549], grad_fn=<MeanBackward1>) tensor([0.8798, 0.0984, 0.0218], grad_fn=<MeanBackward1>) tensor(19.3750, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7.,\n",
      "        9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 6., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -8.217061996459961\n",
      "Validation, uniqueness, novelty:  (0.734, 0.9359673024523161, 0.9228529839883551)\n",
      "[2/200][1622/2079]\tG Loss: 0.3868;D Loss: -0.5545; GP: 0.1405\n",
      "now, we train G 2 times with (prob fake = -0.387, prob real = 0.327)\n",
      "Mean x/edge attr:  tensor([0.7407, 0.1083, 0.1510, 0.0000, 0.9432, 0.0320, 0.0249, 0.7602, 0.0604,\n",
      "        0.1794], grad_fn=<MeanBackward1>) tensor([0.8580, 0.1022, 0.0398], grad_fn=<MeanBackward1>) tensor(20.0312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.796875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7.,\n",
      "        9., 7., 9., 7., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 7., 9., 8., 9., 8., 9.])\n",
      "Sample prob: -9.169005393981934\n",
      "[2/200][1722/2079]\tG Loss: 0.4090;D Loss: -0.7347; GP: 0.1783\n",
      "now, we train G 2 times with (prob fake = -0.409, prob real = 0.293)\n",
      "Mean x/edge attr:  tensor([0.7482, 0.1092, 0.1426, 0.0000, 0.9648, 0.0211, 0.0141, 0.7764, 0.0810,\n",
      "        0.1426], grad_fn=<MeanBackward1>) tensor([0.8729, 0.1088, 0.0183], grad_fn=<MeanBackward1>) tensor(18.8125, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.875 tensor([9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 7., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.164077758789062\n",
      "Validation, uniqueness, novelty:  (0.651, 0.9155145929339478, 0.87248322147651)\n",
      "[2/200][1822/2079]\tG Loss: 0.3626;D Loss: -0.5233; GP: 0.1750\n",
      "now, we train G 2 times with (prob fake = -0.363, prob real = 0.211)\n",
      "Mean x/edge attr:  tensor([0.7255, 0.0909, 0.1836, 0.0000, 0.9643, 0.0303, 0.0053, 0.7629, 0.0731,\n",
      "        0.1640], grad_fn=<MeanBackward1>) tensor([0.8802, 0.1005, 0.0193], grad_fn=<MeanBackward1>) tensor(18.6562, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.765625 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 7., 9., 9., 9., 7., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 7., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 7., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -8.744834899902344\n",
      "[2/200][1922/2079]\tG Loss: 0.2604;D Loss: -0.4857; GP: 0.1513\n",
      "now, we train G 2 times with (prob fake = -0.260, prob real = 0.334)\n",
      "Mean x/edge attr:  tensor([0.6975, 0.1299, 0.1726, 0.0000, 0.9769, 0.0214, 0.0018, 0.7687, 0.0747,\n",
      "        0.1566], grad_fn=<MeanBackward1>) tensor([0.8671, 0.0962, 0.0368], grad_fn=<MeanBackward1>) tensor(18.6875, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.78125 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 7., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 7., 9., 7., 9., 9., 9., 9., 9., 9., 7., 7., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.001008033752441\n",
      "Validation, uniqueness, novelty:  (0.713, 0.9116409537166901, 0.86)\n",
      "[2/200][2022/2079]\tG Loss: 0.3282;D Loss: -0.6577; GP: 0.1250\n",
      "now, we train G 2 times with (prob fake = -0.328, prob real = 0.356)\n",
      "Mean x/edge attr:  tensor([0.7112, 0.1230, 0.1658, 0.0000, 0.9465, 0.0303, 0.0232, 0.8039, 0.0677,\n",
      "        0.1283], grad_fn=<MeanBackward1>) tensor([0.8415, 0.1105, 0.0481], grad_fn=<MeanBackward1>) tensor(18.5312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.765625 tensor([9., 9., 9., 9., 9., 9., 8., 7., 7., 9., 9., 9., 9., 9., 7., 9., 9., 9.,\n",
      "        9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 7., 9., 9., 7., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.708822250366211\n",
      "less than 64\n",
      "[3/200][44/2079]\tG Loss: 0.4244;D Loss: -0.8200; GP: 0.2547\n",
      "now, we train G 2 times with (prob fake = -0.424, prob real = 0.312)\n",
      "Mean x/edge attr:  tensor([0.7092, 0.1275, 0.1634, 0.0000, 0.9695, 0.0287, 0.0018, 0.7720, 0.1005,\n",
      "        0.1275], grad_fn=<MeanBackward1>) tensor([0.8736, 0.1032, 0.0232], grad_fn=<MeanBackward1>) tensor(19.5312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.703125 tensor([9., 9., 9., 7., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 7., 9., 7., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9.,\n",
      "        9., 7., 9., 6., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 7., 9., 9.])\n",
      "Sample prob: -10.305059432983398\n",
      "Validation, uniqueness, novelty:  (0.637, 0.9811616954474097, 0.9536)\n",
      "[3/200][144/2079]\tG Loss: 0.0692;D Loss: -0.7537; GP: 0.1673\n",
      "now, we train G 2 times with (prob fake = -0.069, prob real = 0.520)\n",
      "Mean x/edge attr:  tensor([0.7337, 0.1051, 0.1612, 0.0000, 0.9801, 0.0127, 0.0072, 0.8116, 0.0580,\n",
      "        0.1304], grad_fn=<MeanBackward1>) tensor([0.8670, 0.0943, 0.0387], grad_fn=<MeanBackward1>) tensor(18.5625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.625 tensor([9., 9., 9., 7., 7., 7., 9., 9., 9., 9., 8., 9., 7., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 9., 9., 9., 7., 9., 7., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9.,\n",
      "        7., 7., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.58832836151123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/200][244/2079]\tG Loss: 0.2675;D Loss: -0.7947; GP: 0.2055\n",
      "now, we train G 2 times with (prob fake = -0.268, prob real = 0.484)\n",
      "Mean x/edge attr:  tensor([0.7133, 0.1259, 0.1608, 0.0000, 0.9668, 0.0297, 0.0035, 0.7710, 0.0490,\n",
      "        0.1801], grad_fn=<MeanBackward1>) tensor([0.8603, 0.1082, 0.0315], grad_fn=<MeanBackward1>) tensor(19.3438, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.9375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 8., 9., 9., 9., 9.])\n",
      "Sample prob: -10.014500617980957\n",
      "Validation, uniqueness, novelty:  (0.582, 0.9570446735395189, 0.9245960502692998)\n",
      "[3/200][344/2079]\tG Loss: 0.3964;D Loss: -0.6887; GP: 0.3947\n",
      "now, we train G 2 times with (prob fake = -0.396, prob real = 0.187)\n",
      "Mean x/edge attr:  tensor([0.7012, 0.1107, 0.1880, 0.0000, 0.9684, 0.0193, 0.0123, 0.7715, 0.0861,\n",
      "        0.1424], grad_fn=<MeanBackward1>) tensor([0.8631, 0.1074, 0.0295], grad_fn=<MeanBackward1>) tensor(19.0625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.890625 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        7., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -10.85410213470459\n",
      "[3/200][444/2079]\tG Loss: 0.2758;D Loss: -0.6239; GP: 0.1630\n",
      "now, we train G 2 times with (prob fake = -0.276, prob real = 0.290)\n",
      "Mean x/edge attr:  tensor([0.7160, 0.1499, 0.1340, 0.0000, 0.9559, 0.0194, 0.0247, 0.8183, 0.0935,\n",
      "        0.0882], grad_fn=<MeanBackward1>) tensor([0.8716, 0.1032, 0.0252], grad_fn=<MeanBackward1>) tensor(18.6250, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.859375 tensor([9., 9., 9., 7., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.875844955444336\n",
      "Validation, uniqueness, novelty:  (0.734, 0.9032697547683923, 0.8763197586726998)\n",
      "[3/200][544/2079]\tG Loss: 0.3755;D Loss: -0.6378; GP: 0.0946\n",
      "now, we train G 2 times with (prob fake = -0.375, prob real = 0.301)\n",
      "Mean x/edge attr:  tensor([0.7339, 0.1165, 0.1496, 0.0000, 0.9791, 0.0191, 0.0017, 0.7809, 0.0939,\n",
      "        0.1252], grad_fn=<MeanBackward1>) tensor([0.8695, 0.0870, 0.0435], grad_fn=<MeanBackward1>) tensor(19.0312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.984375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 8., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -10.011617660522461\n",
      "[3/200][644/2079]\tG Loss: 0.4931;D Loss: -0.7779; GP: 0.4990\n",
      "now, we train G 2 times with (prob fake = -0.493, prob real = 0.176)\n",
      "Mean x/edge attr:  tensor([0.7531, 0.0917, 0.1552, 0.0000, 0.9577, 0.0317, 0.0106, 0.8448, 0.0265,\n",
      "        0.1287], grad_fn=<MeanBackward1>) tensor([0.8901, 0.0822, 0.0277], grad_fn=<MeanBackward1>) tensor(18.6250, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.859375 tensor([7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9.,\n",
      "        9., 7., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 8., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.567367553710938\n",
      "Validation, uniqueness, novelty:  (0.679, 0.9396170839469808, 0.9263322884012539)\n",
      "[3/200][744/2079]\tG Loss: 0.4579;D Loss: -0.6284; GP: 0.2489\n",
      "now, we train G 2 times with (prob fake = -0.458, prob real = 0.053)\n",
      "Mean x/edge attr:  tensor([0.7627, 0.0949, 0.1424, 0.0000, 0.9930, 0.0053, 0.0018, 0.8190, 0.0668,\n",
      "        0.1142], grad_fn=<MeanBackward1>) tensor([0.8568, 0.0921, 0.0511], grad_fn=<MeanBackward1>) tensor(18.6562, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.890625 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 7., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 7., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -10.835625648498535\n",
      "[3/200][844/2079]\tG Loss: 0.6431;D Loss: -0.7750; GP: 0.2144\n",
      "now, we train G 2 times with (prob fake = -0.643, prob real = 0.250)\n",
      "Mean x/edge attr:  tensor([0.7030, 0.1538, 0.1431, 0.0000, 0.9714, 0.0215, 0.0072, 0.7961, 0.0698,\n",
      "        0.1342], grad_fn=<MeanBackward1>) tensor([0.8711, 0.1065, 0.0223], grad_fn=<MeanBackward1>) tensor(18.1875, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.734375 tensor([9., 9., 9., 9., 9., 7., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 8., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        7., 9., 8., 9., 9., 9., 7., 9., 7., 9., 9., 9., 7., 9., 9., 9., 9., 7.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.659005165100098\n",
      "Validation, uniqueness, novelty:  (0.619, 0.9402261712439418, 0.9209621993127147)\n",
      "[3/200][944/2079]\tG Loss: 0.5819;D Loss: -0.6773; GP: 0.2299\n",
      "now, we train G 2 times with (prob fake = -0.582, prob real = 0.073)\n",
      "Mean x/edge attr:  tensor([0.6979, 0.1458, 0.1562, 0.0000, 0.9722, 0.0226, 0.0052, 0.8021, 0.0955,\n",
      "        0.1024], grad_fn=<MeanBackward1>) tensor([0.8455, 0.1379, 0.0166], grad_fn=<MeanBackward1>) tensor(19.7188, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 9.0 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.809640884399414\n",
      "[3/200][1044/2079]\tG Loss: 0.5784;D Loss: -0.7580; GP: 0.1362\n",
      "now, we train G 2 times with (prob fake = -0.578, prob real = 0.142)\n",
      "Mean x/edge attr:  tensor([0.7063, 0.1171, 0.1766, 0.0000, 0.9773, 0.0140, 0.0087, 0.7885, 0.0752,\n",
      "        0.1364], grad_fn=<MeanBackward1>) tensor([0.8470, 0.1201, 0.0329], grad_fn=<MeanBackward1>) tensor(19., grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.9375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9.,\n",
      "        9., 9., 8., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.46078872680664\n",
      "Validation, uniqueness, novelty:  (0.766, 0.9099216710182768, 0.9626972740315638)\n",
      "[3/200][1144/2079]\tG Loss: 0.5042;D Loss: -0.7477; GP: 0.3186\n",
      "now, we train G 2 times with (prob fake = -0.504, prob real = 0.315)\n",
      "Mean x/edge attr:  tensor([0.7058, 0.1426, 0.1516, 0.0000, 0.9621, 0.0289, 0.0090, 0.7455, 0.0957,\n",
      "        0.1588], grad_fn=<MeanBackward1>) tensor([0.8705, 0.0961, 0.0334], grad_fn=<MeanBackward1>) tensor(19.1875, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.65625 tensor([9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 7., 9., 7., 7., 9., 9.,\n",
      "        9., 9., 7., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 9., 8., 7., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 7., 9., 9., 9., 9., 7., 9., 9.])\n",
      "Sample prob: -9.25666332244873\n",
      "[3/200][1244/2079]\tG Loss: -0.1023;D Loss: -0.7102; GP: 0.2024\n",
      "now, we train G 2 times with (prob fake = 0.102, prob real = 0.783)\n",
      "Mean x/edge attr:  tensor([0.7410, 0.1048, 0.1543, 0.0000, 0.9810, 0.0114, 0.0076, 0.7943, 0.0610,\n",
      "        0.1448], grad_fn=<MeanBackward1>) tensor([0.8816, 0.1020, 0.0164], grad_fn=<MeanBackward1>) tensor(17.1562, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.203125 tensor([9., 9., 9., 9., 7., 7., 7., 7., 9., 9., 7., 9., 7., 9., 7., 8., 9., 9.,\n",
      "        9., 7., 9., 7., 9., 7., 9., 9., 7., 9., 7., 9., 9., 9., 7., 9., 9., 7.,\n",
      "        7., 9., 7., 9., 9., 9., 9., 7., 9., 7., 7., 9., 7., 7., 7., 7., 7., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 7.])\n",
      "Sample prob: -6.501359462738037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation, uniqueness, novelty:  (0.875, 0.7017142857142857, 0.9006514657980456)\n",
      "[3/200][1344/2079]\tG Loss: 0.1742;D Loss: -0.8725; GP: 0.1668\n",
      "now, we train G 2 times with (prob fake = -0.174, prob real = 0.529)\n",
      "Mean x/edge attr:  tensor([0.7247, 0.1119, 0.1634, 0.0000, 0.9769, 0.0213, 0.0018, 0.7265, 0.1243,\n",
      "        0.1492], grad_fn=<MeanBackward1>) tensor([0.8643, 0.1082, 0.0274], grad_fn=<MeanBackward1>) tensor(20.5000, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.796875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 7., 7., 9., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 7., 9., 9., 9., 7.])\n",
      "Sample prob: -9.450641632080078\n",
      "[3/200][1444/2079]\tG Loss: 0.1988;D Loss: -0.7879; GP: 0.2695\n",
      "now, we train G 2 times with (prob fake = -0.199, prob real = 0.552)\n",
      "Mean x/edge attr:  tensor([0.7424, 0.1002, 0.1521, 0.0054, 0.9875, 0.0107, 0.0018, 0.8104, 0.0805,\n",
      "        0.1091], grad_fn=<MeanBackward1>) tensor([0.8432, 0.0988, 0.0581], grad_fn=<MeanBackward1>) tensor(18.0312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.734375 tensor([9., 9., 9., 9., 7., 7., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 7., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 9., 9., 9., 9., 7., 9., 9., 7., 7., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -7.133626461029053\n",
      "Validation, uniqueness, novelty:  (0.667, 0.7106446776611695, 0.9177215189873418)\n",
      "[3/200][1544/2079]\tG Loss: -0.0241;D Loss: -0.7826; GP: 0.2188\n",
      "now, we train G 2 times with (prob fake = 0.024, prob real = 0.879)\n",
      "Mean x/edge attr:  tensor([0.7113, 0.1322, 0.1426, 0.0139, 0.9670, 0.0226, 0.0104, 0.7617, 0.0957,\n",
      "        0.1426], grad_fn=<MeanBackward1>) tensor([0.8684, 0.1029, 0.0286], grad_fn=<MeanBackward1>) tensor(20.1875, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.984375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.453010559082031\n",
      "[3/200][1644/2079]\tG Loss: 0.5165;D Loss: -1.1622; GP: 0.6662\n",
      "now, we train G 2 times with (prob fake = -0.517, prob real = 0.477)\n",
      "Mean x/edge attr:  tensor([0.7093, 0.1384, 0.1506, 0.0018, 0.9335, 0.0385, 0.0280, 0.7793, 0.0753,\n",
      "        0.1454], grad_fn=<MeanBackward1>) tensor([0.8588, 0.1057, 0.0355], grad_fn=<MeanBackward1>) tensor(19.8125, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.921875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -10.138313293457031\n",
      "Validation, uniqueness, novelty:  (0.461, 0.9349240780911063, 0.9814385150812065)\n",
      "[3/200][1744/2079]\tG Loss: 0.3967;D Loss: -1.1481; GP: 0.2979\n",
      "now, we train G 2 times with (prob fake = -0.397, prob real = 0.799)\n",
      "Mean x/edge attr:  tensor([0.7273, 0.1364, 0.1364, 0.0000, 0.9545, 0.0455, 0.0000, 0.8164, 0.0629,\n",
      "        0.1206], grad_fn=<MeanBackward1>) tensor([0.8800, 0.1091, 0.0109], grad_fn=<MeanBackward1>) tensor(17.1875, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.9375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 8., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -3.156867742538452\n",
      "[3/200][1844/2079]\tG Loss: 0.7092;D Loss: -1.2227; GP: 0.3726\n",
      "now, we train G 2 times with (prob fake = -0.709, prob real = 0.503)\n",
      "Mean x/edge attr:  tensor([0.7016, 0.1257, 0.1728, 0.0000, 0.9738, 0.0244, 0.0017, 0.7871, 0.0750,\n",
      "        0.1379], grad_fn=<MeanBackward1>) tensor([0.8777, 0.1187, 0.0036], grad_fn=<MeanBackward1>) tensor(17.2500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.953125 tensor([9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -3.483828544616699\n",
      "Validation, uniqueness, novelty:  (0.049, 0.9591836734693877, 0.8723404255319149)\n",
      "[3/200][1944/2079]\tG Loss: 0.6568;D Loss: -1.2009; GP: 0.1894\n",
      "now, we train G 2 times with (prob fake = -0.657, prob real = 0.564)\n",
      "Mean x/edge attr:  tensor([0.7465, 0.0955, 0.1476, 0.0104, 0.9618, 0.0330, 0.0052, 0.7899, 0.0729,\n",
      "        0.1372], grad_fn=<MeanBackward1>) tensor([0.9213, 0.0743, 0.0044], grad_fn=<MeanBackward1>) tensor(17.8750, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 9.0 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -3.842071533203125\n",
      "[3/200][2044/2079]\tG Loss: 0.0852;D Loss: -1.1450; GP: 0.3159\n",
      "now, we train G 2 times with (prob fake = -0.085, prob real = 1.058)\n",
      "Mean x/edge attr:  tensor([0.7195, 0.1063, 0.1742, 0.0000, 0.9965, 0.0035, 0.0000, 0.7526, 0.1359,\n",
      "        0.1115], grad_fn=<MeanBackward1>) tensor([0.8333, 0.1023, 0.0644], grad_fn=<MeanBackward1>) tensor(19.4062, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.96875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.040673732757568\n",
      "Validation, uniqueness, novelty:  (0.294, 0.6394557823129252, 0.9414893617021277)\n",
      "less than 64\n",
      "[4/200][66/2079]\tG Loss: 0.3708;D Loss: -1.1728; GP: 0.3261\n",
      "now, we train G 2 times with (prob fake = -0.371, prob real = 0.851)\n",
      "Mean x/edge attr:  tensor([0.7352, 0.1150, 0.1498, 0.0000, 0.9425, 0.0557, 0.0017, 0.7596, 0.0697,\n",
      "        0.1707], grad_fn=<MeanBackward1>) tensor([0.8982, 0.0774, 0.0244], grad_fn=<MeanBackward1>) tensor(19.1875, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.96875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.951124429702759\n",
      "[4/200][166/2079]\tG Loss: 0.7050;D Loss: -1.4488; GP: 0.3042\n",
      "now, we train G 2 times with (prob fake = -0.705, prob real = 0.698)\n",
      "Mean x/edge attr:  tensor([0.6777, 0.1185, 0.2038, 0.0000, 0.9774, 0.0122, 0.0105, 0.8101, 0.0627,\n",
      "        0.1272], grad_fn=<MeanBackward1>) tensor([0.8669, 0.1147, 0.0184], grad_fn=<MeanBackward1>) tensor(17.8438, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.96875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.518979549407959\n",
      "Validation, uniqueness, novelty:  (0.006, 1.0, 1.0)\n",
      "[4/200][266/2079]\tG Loss: 0.8686;D Loss: -1.3701; GP: 0.2884\n",
      "now, we train G 2 times with (prob fake = -0.869, prob real = 0.610)\n",
      "Mean x/edge attr:  tensor([0.6997, 0.1233, 0.1667, 0.0104, 0.9809, 0.0174, 0.0017, 0.7396, 0.1146,\n",
      "        0.1458], grad_fn=<MeanBackward1>) tensor([0.8602, 0.0929, 0.0469], grad_fn=<MeanBackward1>) tensor(19., grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 9.0 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.634915828704834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/200][366/2079]\tG Loss: 0.9974;D Loss: -1.6109; GP: 0.8462\n",
      "now, we train G 2 times with (prob fake = -0.997, prob real = 0.683)\n",
      "Mean x/edge attr:  tensor([0.7183, 0.1409, 0.1374, 0.0035, 0.9617, 0.0383, 0.0000, 0.7652, 0.0939,\n",
      "        0.1409], grad_fn=<MeanBackward1>) tensor([0.8515, 0.1112, 0.0373], grad_fn=<MeanBackward1>) tensor(19.2500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.984375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.707549571990967\n",
      "Validation, uniqueness, novelty:  (0.0, 0, 0)\n",
      "[4/200][466/2079]\tG Loss: 1.0860;D Loss: -1.5111; GP: 0.2188\n",
      "now, we train G 2 times with (prob fake = -1.086, prob real = 0.511)\n",
      "Mean x/edge attr:  tensor([0.7687, 0.0835, 0.1478, 0.0000, 0.9757, 0.0174, 0.0070, 0.7600, 0.0939,\n",
      "        0.1461], grad_fn=<MeanBackward1>) tensor([0.8994, 0.0769, 0.0238], grad_fn=<MeanBackward1>) tensor(19.7188, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.984375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.509681463241577\n",
      "[4/200][566/2079]\tG Loss: 1.0069;D Loss: -1.4781; GP: 0.1768\n",
      "now, we train G 2 times with (prob fake = -1.007, prob real = 0.441)\n",
      "Mean x/edge attr:  tensor([0.7257, 0.1198, 0.1545, 0.0000, 0.9670, 0.0174, 0.0156, 0.7622, 0.0538,\n",
      "        0.1840], grad_fn=<MeanBackward1>) tensor([0.8452, 0.1062, 0.0486], grad_fn=<MeanBackward1>) tensor(19.2812, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 9.0 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.6099026203155518\n",
      "Validation, uniqueness, novelty:  (0.0, 0, 0)\n",
      "[4/200][666/2079]\tG Loss: 0.7078;D Loss: -1.7035; GP: 0.3696\n",
      "now, we train G 2 times with (prob fake = -0.708, prob real = 0.988)\n",
      "Mean x/edge attr:  tensor([0.7500, 0.0992, 0.1508, 0.0000, 0.9802, 0.0179, 0.0020, 0.8552, 0.0437,\n",
      "        0.1012], grad_fn=<MeanBackward1>) tensor([0.8745, 0.1124, 0.0131], grad_fn=<MeanBackward1>) tensor(15.5625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 7.875 tensor([9., 7., 9., 7., 7., 9., 7., 9., 9., 9., 7., 7., 9., 7., 9., 7., 9., 9.,\n",
      "        9., 7., 7., 7., 9., 7., 9., 7., 9., 7., 7., 7., 9., 7., 9., 9., 9., 7.,\n",
      "        7., 7., 7., 7., 9., 7., 7., 7., 9., 7., 7., 7., 7., 9., 9., 7., 9., 7.,\n",
      "        9., 7., 9., 7., 7., 9., 9., 7., 9., 7.])\n",
      "Sample prob: -1.4676378965377808\n",
      "[4/200][766/2079]\tG Loss: 0.4449;D Loss: -1.6470; GP: 0.7838\n",
      "now, we train G 2 times with (prob fake = -0.445, prob real = 1.157)\n",
      "Mean x/edge attr:  tensor([0.7316, 0.1082, 0.1580, 0.0022, 0.9957, 0.0043, 0.0000, 0.8745, 0.0693,\n",
      "        0.0563], grad_fn=<MeanBackward1>) tensor([0.8310, 0.1354, 0.0336], grad_fn=<MeanBackward1>) tensor(15.3438, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 7.21875 tensor([7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 9., 9., 7., 7., 7.,\n",
      "        7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n",
      "        7., 7., 7., 7., 9., 7., 9., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n",
      "        7., 7., 7., 7., 7., 9., 7., 9., 7., 9.])\n",
      "Sample prob: -0.7188867330551147\n",
      "Validation, uniqueness, novelty:  (0.002, 1.0, 1.0)\n",
      "[4/200][866/2079]\tG Loss: 0.4237;D Loss: -1.5840; GP: 0.2118\n",
      "now, we train G 2 times with (prob fake = -0.424, prob real = 1.151)\n",
      "Mean x/edge attr:  tensor([0.6957, 0.1095, 0.1947, 0.0000, 0.9858, 0.0061, 0.0081, 0.7992, 0.0730,\n",
      "        0.1278], grad_fn=<MeanBackward1>) tensor([0.8554, 0.1138, 0.0308], grad_fn=<MeanBackward1>) tensor(16.7500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 7.703125 tensor([9., 7., 9., 7., 9., 7., 7., 7., 7., 7., 7., 7., 9., 7., 7., 7., 7., 9.,\n",
      "        7., 7., 7., 7., 9., 7., 9., 7., 9., 9., 7., 9., 9., 7., 7., 7., 7., 7.,\n",
      "        7., 7., 9., 7., 9., 9., 7., 7., 9., 7., 7., 9., 9., 9., 7., 9., 7., 7.,\n",
      "        7., 9., 6., 7., 7., 9., 7., 9., 9., 7.])\n",
      "Sample prob: -1.7416603565216064\n",
      "[4/200][966/2079]\tG Loss: 0.4562;D Loss: -1.6355; GP: 0.3013\n",
      "now, we train G 2 times with (prob fake = -0.456, prob real = 1.129)\n",
      "Mean x/edge attr:  tensor([0.7213, 0.1250, 0.1537, 0.0000, 0.9795, 0.0102, 0.0102, 0.7930, 0.0922,\n",
      "        0.1148], grad_fn=<MeanBackward1>) tensor([0.8585, 0.0983, 0.0432], grad_fn=<MeanBackward1>) tensor(17., grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 7.625 tensor([9., 7., 7., 9., 9., 7., 7., 7., 7., 7., 9., 9., 7., 9., 9., 7., 7., 7.,\n",
      "        7., 7., 7., 9., 7., 7., 7., 9., 7., 7., 7., 7., 9., 9., 9., 7., 9., 9.,\n",
      "        7., 7., 7., 7., 7., 7., 9., 7., 7., 7., 7., 7., 7., 7., 7., 7., 9., 7.,\n",
      "        7., 7., 7., 9., 9., 9., 9., 7., 7., 7.])\n",
      "Sample prob: -1.4020273685455322\n",
      "Validation, uniqueness, novelty:  (0.0, 0, 0)\n",
      "[4/200][1066/2079]\tG Loss: 0.5710;D Loss: -1.4879; GP: 0.5783\n",
      "now, we train G 2 times with (prob fake = -0.571, prob real = 1.025)\n",
      "Mean x/edge attr:  tensor([0.6562, 0.1745, 0.1693, 0.0000, 0.9075, 0.0855, 0.0070, 0.8290, 0.0506,\n",
      "        0.1204], grad_fn=<MeanBackward1>) tensor([0.8752, 0.1125, 0.0123], grad_fn=<MeanBackward1>) tensor(17.7812, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.953125 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.705273151397705\n",
      "[4/200][1166/2079]\tG Loss: 0.9274;D Loss: -1.5269; GP: 0.1984\n",
      "now, we train G 2 times with (prob fake = -0.927, prob real = 0.588)\n",
      "Mean x/edge attr:  tensor([0.7282, 0.0993, 0.1725, 0.0000, 0.9408, 0.0540, 0.0052, 0.7857, 0.0679,\n",
      "        0.1463], grad_fn=<MeanBackward1>) tensor([0.8766, 0.1058, 0.0176], grad_fn=<MeanBackward1>) tensor(19.5000, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.96875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -3.1780831813812256\n",
      "Validation, uniqueness, novelty:  (0.0, 0, 0)\n",
      "[4/200][1266/2079]\tG Loss: 0.1557;D Loss: -1.3595; GP: 0.1715\n",
      "now, we train G 2 times with (prob fake = -0.156, prob real = 1.208)\n",
      "Mean x/edge attr:  tensor([0.7513, 0.0678, 0.1791, 0.0017, 0.9896, 0.0000, 0.0104, 0.7965, 0.0870,\n",
      "        0.1165], grad_fn=<MeanBackward1>) tensor([0.8840, 0.0899, 0.0261], grad_fn=<MeanBackward1>) tensor(18.5938, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.984375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -3.3308677673339844\n",
      "[4/200][1366/2079]\tG Loss: 0.5061;D Loss: -1.5718; GP: 0.4754\n",
      "now, we train G 2 times with (prob fake = -0.506, prob real = 1.022)\n",
      "Mean x/edge attr:  tensor([0.6969, 0.1167, 0.1655, 0.0209, 0.9268, 0.0679, 0.0052, 0.7909, 0.1080,\n",
      "        0.1010], grad_fn=<MeanBackward1>) tensor([0.9039, 0.0789, 0.0172], grad_fn=<MeanBackward1>) tensor(18.2188, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.96875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 7., 9., 9., 9., 9.])\n",
      "Sample prob: -3.4924533367156982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation, uniqueness, novelty:  (0.001, 1.0, 1.0)\n",
      "[4/200][1466/2079]\tG Loss: 0.9246;D Loss: -1.5251; GP: 0.2346\n",
      "now, we train G 2 times with (prob fake = -0.925, prob real = 0.625)\n",
      "Mean x/edge attr:  tensor([0.7235, 0.1200, 0.1548, 0.0017, 0.9600, 0.0400, 0.0000, 0.7861, 0.0713,\n",
      "        0.1426], grad_fn=<MeanBackward1>) tensor([0.8607, 0.1235, 0.0158], grad_fn=<MeanBackward1>) tensor(18.8438, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.984375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -2.9952638149261475\n",
      "[4/200][1566/2079]\tG Loss: 1.1947;D Loss: -1.5755; GP: 0.0811\n",
      "now, we train G 2 times with (prob fake = -1.195, prob real = 0.443)\n",
      "Mean x/edge attr:  tensor([0.7247, 0.1150, 0.1603, 0.0000, 1.0000, 0.0000, 0.0000, 0.7997, 0.0923,\n",
      "        0.1080], grad_fn=<MeanBackward1>) tensor([0.8462, 0.0861, 0.0677], grad_fn=<MeanBackward1>) tensor(18.6875, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.96875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -3.004213571548462\n",
      "Validation, uniqueness, novelty:  (0.0, 0, 0)\n",
      "[4/200][1666/2079]\tG Loss: 1.0491;D Loss: -0.0132; GP: 2.4673\n",
      "now, we train G 1 times with (prob fake = -1.049, prob real = -1.111)\n",
      "Mean x/edge attr:  tensor([0.7292, 0.1528, 0.1181, 0.0000, 0.9983, 0.0017, 0.0000, 0.6111, 0.1684,\n",
      "        0.2205], grad_fn=<MeanBackward1>) tensor([0.7934, 0.1954, 0.0112], grad_fn=<MeanBackward1>) tensor(23.7500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 9.0 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -10.178837776184082\n",
      "[4/200][1766/2079]\tG Loss: 0.5139;D Loss: -0.0819; GP: 1.0797\n",
      "now, we train G 1 times with (prob fake = -0.514, prob real = -0.421)\n",
      "Mean x/edge attr:  tensor([0.7021, 0.1167, 0.1812, 0.0000, 0.9965, 0.0017, 0.0017, 0.7892, 0.0505,\n",
      "        0.1603], grad_fn=<MeanBackward1>) tensor([0.8628, 0.1220, 0.0152], grad_fn=<MeanBackward1>) tensor(20.5000, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.96875 tensor([9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -11.532023429870605\n",
      "Validation, uniqueness, novelty:  (0.333, 0.987987987987988, 0.9483282674772037)\n",
      "[4/200][1866/2079]\tG Loss: 0.3946;D Loss: -0.0798; GP: 0.3294\n",
      "now, we train G 1 times with (prob fake = -0.395, prob real = -0.317)\n",
      "Mean x/edge attr:  tensor([0.7133, 0.1573, 0.1276, 0.0017, 0.9528, 0.0437, 0.0035, 0.7815, 0.1066,\n",
      "        0.1119], grad_fn=<MeanBackward1>) tensor([0.8302, 0.1333, 0.0365], grad_fn=<MeanBackward1>) tensor(19.6875, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.9375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -11.49505615234375\n",
      "[4/200][1966/2079]\tG Loss: 0.3556;D Loss: -0.1717; GP: 0.2373\n",
      "now, we train G 1 times with (prob fake = -0.356, prob real = -0.239)\n",
      "Mean x/edge attr:  tensor([0.7408, 0.1086, 0.1506, 0.0000, 0.9650, 0.0350, 0.0000, 0.8109, 0.0385,\n",
      "        0.1506], grad_fn=<MeanBackward1>) tensor([0.8508, 0.1161, 0.0331], grad_fn=<MeanBackward1>) tensor(19.3750, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.921875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 7., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -10.767370223999023\n",
      "Validation, uniqueness, novelty:  (0.4, 0.99, 0.9848484848484849)\n",
      "[4/200][2066/2079]\tG Loss: 0.2086;D Loss: -0.1514; GP: 0.1600\n",
      "now, we train G 1 times with (prob fake = -0.209, prob real = -0.019)\n",
      "Mean x/edge attr:  tensor([0.6991, 0.1575, 0.1434, 0.0000, 0.9912, 0.0035, 0.0053, 0.8372, 0.0655,\n",
      "        0.0973], grad_fn=<MeanBackward1>) tensor([0.8315, 0.1015, 0.0670], grad_fn=<MeanBackward1>) tensor(16.7812, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.828125 tensor([9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 8.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 8., 9., 8., 9., 9., 9., 8., 9., 9., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 8., 8., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.760599613189697\n",
      "less than 64\n",
      "[5/200][88/2079]\tG Loss: 0.5840;D Loss: -0.2732; GP: 0.1790\n",
      "now, we train G 2 times with (prob fake = -0.584, prob real = -0.343)\n",
      "Mean x/edge attr:  tensor([0.7373, 0.1086, 0.1524, 0.0018, 0.9807, 0.0123, 0.0070, 0.7688, 0.0928,\n",
      "        0.1384], grad_fn=<MeanBackward1>) tensor([0.8611, 0.0860, 0.0529], grad_fn=<MeanBackward1>) tensor(17.4375, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.921875 tensor([9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 9., 9., 9.])\n",
      "Sample prob: -5.281106948852539\n",
      "Validation, uniqueness, novelty:  (0.806, 0.7320099255583127, 0.9542372881355933)\n",
      "[5/200][188/2079]\tG Loss: 0.2049;D Loss: -0.2090; GP: 0.1890\n",
      "now, we train G 2 times with (prob fake = -0.205, prob real = 0.057)\n",
      "Mean x/edge attr:  tensor([0.7552, 0.0944, 0.1416, 0.0087, 0.9913, 0.0070, 0.0017, 0.7815, 0.0717,\n",
      "        0.1469], grad_fn=<MeanBackward1>) tensor([0.8649, 0.0938, 0.0414], grad_fn=<MeanBackward1>) tensor(18.5000, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.9375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -4.926074028015137\n",
      "[5/200][288/2079]\tG Loss: 0.2159;D Loss: -0.2490; GP: 0.2872\n",
      "now, we train G 2 times with (prob fake = -0.216, prob real = 0.067)\n",
      "Mean x/edge attr:  tensor([0.7269, 0.1175, 0.1555, 0.0000, 0.9747, 0.0199, 0.0054, 0.7269, 0.0705,\n",
      "        0.2025], grad_fn=<MeanBackward1>) tensor([0.8754, 0.0970, 0.0276], grad_fn=<MeanBackward1>) tensor(19.8125, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.640625 tensor([8., 9., 8., 8., 9., 9., 9., 8., 8., 8., 9., 8., 9., 8., 9., 8., 8., 9.,\n",
      "        8., 9., 8., 9., 9., 9., 8., 8., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9.,\n",
      "        9., 9., 8., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 8., 7., 9., 9.])\n",
      "Sample prob: -4.733582973480225\n",
      "Validation, uniqueness, novelty:  (0.477, 0.7568134171907757, 0.9833795013850416)\n",
      "[5/200][388/2079]\tG Loss: 0.2345;D Loss: -0.3277; GP: 0.2828\n",
      "now, we train G 2 times with (prob fake = -0.234, prob real = 0.097)\n",
      "Mean x/edge attr:  tensor([0.7752, 0.0683, 0.1565, 0.0000, 0.9910, 0.0072, 0.0018, 0.8759, 0.0450,\n",
      "        0.0791], grad_fn=<MeanBackward1>) tensor([0.8411, 0.0961, 0.0628], grad_fn=<MeanBackward1>) tensor(17.4062, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.6875 tensor([9., 9., 8., 9., 8., 8., 9., 8., 9., 9., 8., 9., 8., 8., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 8., 9., 8., 8., 9., 9., 9., 8.,\n",
      "        8., 8., 8., 8., 9., 9., 9., 9., 9., 9., 9., 8., 9., 8., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 8., 9., 9.])\n",
      "Sample prob: -4.790038108825684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/200][488/2079]\tG Loss: 0.2412;D Loss: -0.3836; GP: 0.0945\n",
      "now, we train G 2 times with (prob fake = -0.241, prob real = 0.079)\n",
      "Mean x/edge attr:  tensor([0.7531, 0.0894, 0.1538, 0.0036, 0.9821, 0.0179, 0.0000, 0.7800, 0.0859,\n",
      "        0.1342], grad_fn=<MeanBackward1>) tensor([0.8624, 0.1063, 0.0313], grad_fn=<MeanBackward1>) tensor(18.9688, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.734375 tensor([9., 9., 9., 8., 9., 9., 8., 9., 9., 9., 9., 9., 8., 9., 9., 9., 8., 9.,\n",
      "        8., 9., 8., 9., 8., 9., 8., 9., 8., 9., 8., 9., 9., 9., 9., 9., 8., 7.,\n",
      "        9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 9., 8., 9.])\n",
      "Sample prob: -7.327522277832031\n",
      "Validation, uniqueness, novelty:  (0.549, 0.8706739526411658, 0.9267782426778243)\n",
      "[5/200][588/2079]\tG Loss: 0.3731;D Loss: -0.3397; GP: 0.0758\n",
      "now, we train G 2 times with (prob fake = -0.373, prob real = -0.030)\n",
      "Mean x/edge attr:  tensor([0.7092, 0.1684, 0.1170, 0.0053, 0.9273, 0.0603, 0.0124, 0.7979, 0.0904,\n",
      "        0.1117], grad_fn=<MeanBackward1>) tensor([0.8515, 0.1090, 0.0395], grad_fn=<MeanBackward1>) tensor(19.7812, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.8125 tensor([9., 8., 8., 9., 8., 9., 8., 9., 9., 8., 9., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 8., 9., 8.,\n",
      "        9., 9., 9., 9., 8., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.438455581665039\n",
      "[5/200][688/2079]\tG Loss: 0.4670;D Loss: -0.3730; GP: 0.1030\n",
      "now, we train G 2 times with (prob fake = -0.467, prob real = -0.073)\n",
      "Mean x/edge attr:  tensor([0.7128, 0.1506, 0.1366, 0.0000, 0.9615, 0.0298, 0.0088, 0.7618, 0.0893,\n",
      "        0.1489], grad_fn=<MeanBackward1>) tensor([0.8497, 0.1168, 0.0335], grad_fn=<MeanBackward1>) tensor(20.0625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.921875 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 8., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -6.072380065917969\n",
      "Validation, uniqueness, novelty:  (0.803, 0.5902864259028643, 0.9873417721518988)\n",
      "[5/200][788/2079]\tG Loss: 0.0059;D Loss: -0.2355; GP: 0.0707\n",
      "now, we train G 2 times with (prob fake = -0.006, prob real = 0.194)\n",
      "Mean x/edge attr:  tensor([0.7232, 0.0946, 0.1821, 0.0000, 0.9786, 0.0196, 0.0018, 0.8054, 0.0821,\n",
      "        0.1125], grad_fn=<MeanBackward1>) tensor([0.8434, 0.1181, 0.0385], grad_fn=<MeanBackward1>) tensor(18.6562, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.75 tensor([9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 8., 8.,\n",
      "        8., 8., 8., 9., 9., 9., 8., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 8., 8., 8., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 8., 9., 9., 9., 9., 8.])\n",
      "Sample prob: -7.716396808624268\n",
      "[5/200][888/2079]\tG Loss: -0.0032;D Loss: -0.2840; GP: 0.1009\n",
      "now, we train G 2 times with (prob fake = 0.003, prob real = 0.362)\n",
      "Mean x/edge attr:  tensor([0.6993, 0.1584, 0.1423, 0.0000, 0.9609, 0.0231, 0.0160, 0.7722, 0.0765,\n",
      "        0.1512], grad_fn=<MeanBackward1>) tensor([0.8428, 0.1151, 0.0421], grad_fn=<MeanBackward1>) tensor(19.2812, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.78125 tensor([8., 9., 9., 9., 9., 8., 9., 9., 9., 9., 8., 9., 9., 8., 8., 8., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 8., 9., 8.,\n",
      "        9., 9., 9., 8., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 8., 8., 9., 9., 8., 9., 9.])\n",
      "Sample prob: -7.405029773712158\n",
      "Validation, uniqueness, novelty:  (0.678, 0.8525073746312685, 0.9446366782006921)\n",
      "[5/200][988/2079]\tG Loss: 0.1655;D Loss: -0.3678; GP: 0.0952\n",
      "now, we train G 2 times with (prob fake = -0.165, prob real = 0.122)\n",
      "Mean x/edge attr:  tensor([0.7339, 0.1217, 0.1443, 0.0000, 0.9948, 0.0017, 0.0035, 0.7478, 0.1148,\n",
      "        0.1374], grad_fn=<MeanBackward1>) tensor([0.8728, 0.0965, 0.0306], grad_fn=<MeanBackward1>) tensor(19.9062, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.984375 tensor([9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -6.612091064453125\n",
      "[5/200][1088/2079]\tG Loss: -0.1098;D Loss: -0.3155; GP: 0.1058\n",
      "now, we train G 2 times with (prob fake = 0.110, prob real = 0.404)\n",
      "Mean x/edge attr:  tensor([0.7316, 0.0974, 0.1710, 0.0000, 0.9669, 0.0294, 0.0037, 0.8107, 0.0735,\n",
      "        0.1158], grad_fn=<MeanBackward1>) tensor([0.8714, 0.0961, 0.0326], grad_fn=<MeanBackward1>) tensor(18.2188, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.5 tensor([8., 8., 8., 9., 9., 8., 8., 9., 8., 9., 8., 9., 8., 8., 8., 9., 8., 9.,\n",
      "        8., 9., 8., 8., 9., 9., 8., 9., 8., 9., 9., 8., 8., 8., 8., 8., 8., 9.,\n",
      "        8., 8., 9., 9., 9., 9., 8., 9., 8., 9., 9., 8., 9., 8., 8., 8., 8., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -6.324634075164795\n",
      "Validation, uniqueness, novelty:  (0.671, 0.6721311475409836, 0.9290465631929047)\n",
      "[5/200][1188/2079]\tG Loss: 0.1448;D Loss: -0.5871; GP: 0.0973\n",
      "now, we train G 2 times with (prob fake = -0.145, prob real = 0.479)\n",
      "Mean x/edge attr:  tensor([0.7731, 0.1125, 0.1143, 0.0000, 0.9183, 0.0799, 0.0018, 0.7822, 0.0635,\n",
      "        0.1543], grad_fn=<MeanBackward1>) tensor([0.9120, 0.0643, 0.0237], grad_fn=<MeanBackward1>) tensor(18.4688, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.609375 tensor([9., 8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 8., 8., 8.,\n",
      "        8., 8., 9., 9., 9., 9., 8., 8., 9., 9., 9., 9., 9., 8., 8., 9., 8., 8.,\n",
      "        9., 9., 9., 8., 9., 9., 8., 9., 8., 9., 8., 8., 8., 9., 8., 8., 9., 9.,\n",
      "        8., 9., 8., 9., 9., 8., 9., 8., 9., 9.])\n",
      "Sample prob: -4.2325263023376465\n",
      "[5/200][1288/2079]\tG Loss: -0.0613;D Loss: -0.6984; GP: 0.1921\n",
      "now, we train G 2 times with (prob fake = 0.061, prob real = 0.735)\n",
      "Mean x/edge attr:  tensor([0.7778, 0.0556, 0.1667, 0.0000, 0.9685, 0.0074, 0.0241, 0.7870, 0.0981,\n",
      "        0.1148], grad_fn=<MeanBackward1>) tensor([0.8918, 0.0790, 0.0292], grad_fn=<MeanBackward1>) tensor(18.1875, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.4375 tensor([9., 8., 8., 8., 9., 8., 8., 8., 9., 9., 8., 9., 9., 9., 8., 9., 9., 8.,\n",
      "        8., 8., 8., 9., 9., 8., 8., 9., 8., 8., 8., 9., 9., 8., 8., 8., 8., 8.,\n",
      "        9., 8., 9., 9., 9., 8., 9., 8., 9., 8., 9., 9., 8., 9., 8., 9., 8., 9.,\n",
      "        8., 9., 8., 8., 9., 8., 8., 8., 8., 9.])\n",
      "Sample prob: -4.2078986167907715\n",
      "Validation, uniqueness, novelty:  (0.646, 0.3978328173374613, 0.953307392996109)\n",
      "[5/200][1388/2079]\tG Loss: -0.3964;D Loss: -0.3005; GP: 0.1355\n",
      "now, we train G 2 times with (prob fake = 0.396, prob real = 0.724)\n",
      "Mean x/edge attr:  tensor([0.7074, 0.0796, 0.2000, 0.0130, 0.9537, 0.0333, 0.0130, 0.7796, 0.0815,\n",
      "        0.1389], grad_fn=<MeanBackward1>) tensor([0.8759, 0.1241, 0.0000], grad_fn=<MeanBackward1>) tensor(17.2500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.4375 tensor([9., 9., 8., 8., 8., 8., 8., 9., 9., 9., 8., 9., 8., 8., 9., 8., 9., 9.,\n",
      "        8., 8., 8., 9., 8., 9., 9., 9., 9., 8., 8., 8., 9., 9., 9., 8., 8., 9.,\n",
      "        9., 9., 8., 8., 9., 8., 8., 8., 8., 9., 8., 8., 8., 8., 8., 8., 9., 8.,\n",
      "        9., 9., 8., 8., 8., 9., 8., 8., 9., 9.])\n",
      "Sample prob: -4.26015567779541\n",
      "[5/200][1488/2079]\tG Loss: 0.1419;D Loss: -0.6112; GP: 0.0924\n",
      "now, we train G 2 times with (prob fake = -0.142, prob real = 0.480)\n",
      "Mean x/edge attr:  tensor([0.7261, 0.0613, 0.1964, 0.0162, 0.9730, 0.0252, 0.0018, 0.8180, 0.0126,\n",
      "        0.1694], grad_fn=<MeanBackward1>) tensor([0.8767, 0.1233, 0.0000], grad_fn=<MeanBackward1>) tensor(18.2500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.671875 tensor([9., 9., 8., 9., 9., 9., 9., 9., 8., 9., 8., 8., 9., 8., 8., 9., 8., 9.,\n",
      "        9., 9., 7., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 8., 8.,\n",
      "        9., 9., 8., 9., 9., 9., 9., 9., 8., 7., 8., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 8., 9., 9., 9., 8., 9., 9.])\n",
      "Sample prob: -5.080420970916748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation, uniqueness, novelty:  (0.841, 0.3626634958382878, 1.0)\n",
      "[5/200][1588/2079]\tG Loss: -0.0962;D Loss: -0.4696; GP: 0.1057\n",
      "now, we train G 2 times with (prob fake = 0.096, prob real = 0.534)\n",
      "Mean x/edge attr:  tensor([0.7452, 0.1274, 0.1274, 0.0000, 0.9651, 0.0332, 0.0017, 0.7225, 0.0628,\n",
      "        0.2147], grad_fn=<MeanBackward1>) tensor([0.9038, 0.0612, 0.0351], grad_fn=<MeanBackward1>) tensor(19.1562, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.953125 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 9., 9., 9.])\n",
      "Sample prob: -5.270854949951172\n",
      "[5/200][1688/2079]\tG Loss: 0.4294;D Loss: -0.5865; GP: 0.1223\n",
      "now, we train G 2 times with (prob fake = -0.429, prob real = 0.210)\n",
      "Mean x/edge attr:  tensor([0.7365, 0.0995, 0.1640, 0.0000, 0.9791, 0.0175, 0.0035, 0.7609, 0.0960,\n",
      "        0.1431], grad_fn=<MeanBackward1>) tensor([0.8857, 0.0851, 0.0292], grad_fn=<MeanBackward1>) tensor(19.2812, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.953125 tensor([9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.937891960144043\n",
      "Validation, uniqueness, novelty:  (0.787, 0.4714104193138501, 0.9245283018867925)\n",
      "[5/200][1788/2079]\tG Loss: 0.1250;D Loss: -0.4350; GP: 0.1094\n",
      "now, we train G 2 times with (prob fake = -0.125, prob real = 0.393)\n",
      "Mean x/edge attr:  tensor([0.7276, 0.0931, 0.1775, 0.0018, 0.9596, 0.0281, 0.0123, 0.7856, 0.0756,\n",
      "        0.1388], grad_fn=<MeanBackward1>) tensor([0.8962, 0.0815, 0.0223], grad_fn=<MeanBackward1>) tensor(18.2188, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.890625 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 8., 9., 8., 8., 8., 9., 8.])\n",
      "Sample prob: -5.076430320739746\n",
      "[5/200][1888/2079]\tG Loss: 0.3394;D Loss: -1.0550; GP: 0.1789\n",
      "now, we train G 2 times with (prob fake = -0.339, prob real = 0.758)\n",
      "Mean x/edge attr:  tensor([0.7014, 0.1111, 0.1771, 0.0104, 0.9809, 0.0104, 0.0087, 0.7500, 0.1267,\n",
      "        0.1233], grad_fn=<MeanBackward1>) tensor([0.8616, 0.0992, 0.0392], grad_fn=<MeanBackward1>) tensor(19.5312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 9.0 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.95294713973999\n",
      "Validation, uniqueness, novelty:  (0.163, 0.9877300613496932, 0.9627329192546584)\n",
      "[5/200][1988/2079]\tG Loss: 0.3667;D Loss: -0.8866; GP: 0.1244\n",
      "now, we train G 2 times with (prob fake = -0.367, prob real = 0.402)\n",
      "Mean x/edge attr:  tensor([0.7160, 0.1045, 0.1760, 0.0035, 0.9826, 0.0087, 0.0087, 0.7509, 0.0784,\n",
      "        0.1707], grad_fn=<MeanBackward1>) tensor([0.8569, 0.1171, 0.0259], grad_fn=<MeanBackward1>) tensor(19.8750, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.96875 tensor([9., 9., 9., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -8.147642135620117\n",
      "less than 64\n",
      "[6/200][10/2079]\tG Loss: 0.0427;D Loss: -0.5630; GP: 0.1529\n",
      "now, we train G 2 times with (prob fake = -0.043, prob real = 0.501)\n",
      "Mean x/edge attr:  tensor([0.6986, 0.1330, 0.1684, 0.0000, 0.9716, 0.0195, 0.0089, 0.7713, 0.0762,\n",
      "        0.1525], grad_fn=<MeanBackward1>) tensor([0.8781, 0.0914, 0.0305], grad_fn=<MeanBackward1>) tensor(18.9688, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.8125 tensor([9., 7., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 8., 9.,\n",
      "        8., 9., 8., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -8.88670539855957\n",
      "Validation, uniqueness, novelty:  (0.649, 0.7550077041602465, 0.9183673469387755)\n",
      "[6/200][110/2079]\tG Loss: 0.1953;D Loss: -0.2845; GP: 0.1023\n",
      "now, we train G 2 times with (prob fake = -0.195, prob real = 0.119)\n",
      "Mean x/edge attr:  tensor([0.7252, 0.1188, 0.1560, 0.0000, 0.9681, 0.0195, 0.0124, 0.7890, 0.0550,\n",
      "        0.1560], grad_fn=<MeanBackward1>) tensor([0.8651, 0.1069, 0.0280], grad_fn=<MeanBackward1>) tensor(19., grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.8125 tensor([9., 9., 8., 9., 9., 9., 9., 7., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 8., 8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 8., 9.,\n",
      "        9., 8., 9., 9., 8., 9., 9., 9., 8., 9.])\n",
      "Sample prob: -8.358759880065918\n",
      "[6/200][210/2079]\tG Loss: 0.0159;D Loss: -0.1876; GP: 0.0963\n",
      "now, we train G 1 times with (prob fake = -0.016, prob real = 0.235)\n",
      "Mean x/edge attr:  tensor([0.7263, 0.1053, 0.1684, 0.0000, 0.9772, 0.0211, 0.0018, 0.7842, 0.0526,\n",
      "        0.1632], grad_fn=<MeanBackward1>) tensor([0.8597, 0.1238, 0.0165], grad_fn=<MeanBackward1>) tensor(18.9375, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.90625 tensor([9., 9., 9., 8., 8., 8., 9., 9., 9., 9., 8., 9., 9., 9., 8., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -8.472517013549805\n",
      "Validation, uniqueness, novelty:  (0.815, 0.7411042944785277, 0.9254966887417219)\n",
      "[6/200][310/2079]\tG Loss: 0.2420;D Loss: -0.4035; GP: 0.0962\n",
      "now, we train G 2 times with (prob fake = -0.242, prob real = 0.150)\n",
      "Mean x/edge attr:  tensor([0.6949, 0.1393, 0.1658, 0.0000, 0.9718, 0.0229, 0.0053, 0.7478, 0.1182,\n",
      "        0.1340], grad_fn=<MeanBackward1>) tensor([0.8706, 0.1086, 0.0208], grad_fn=<MeanBackward1>) tensor(19.5625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.859375 tensor([9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 8., 9., 9., 8., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 7., 8., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.32975959777832\n",
      "[6/200][410/2079]\tG Loss: 0.3158;D Loss: -0.5970; GP: 0.1650\n",
      "now, we train G 2 times with (prob fake = -0.316, prob real = 0.432)\n",
      "Mean x/edge attr:  tensor([0.7120, 0.1360, 0.1519, 0.0000, 0.9470, 0.0442, 0.0088, 0.7226, 0.0565,\n",
      "        0.2208], grad_fn=<MeanBackward1>) tensor([0.8825, 0.0899, 0.0276], grad_fn=<MeanBackward1>) tensor(19.8125, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.84375 tensor([9., 9., 9., 9., 9., 9., 8., 9., 9., 8., 9., 9., 8., 9., 9., 8., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 8., 8., 9., 9., 9., 9., 8.])\n",
      "Sample prob: -9.979522705078125\n",
      "Validation, uniqueness, novelty:  (0.723, 0.8589211618257261, 0.9468599033816425)\n",
      "[6/200][510/2079]\tG Loss: 0.1197;D Loss: -0.5096; GP: 0.1206\n",
      "now, we train G 2 times with (prob fake = -0.120, prob real = 0.295)\n",
      "Mean x/edge attr:  tensor([0.6720, 0.1623, 0.1658, 0.0000, 0.9577, 0.0300, 0.0123, 0.7743, 0.0882,\n",
      "        0.1376], grad_fn=<MeanBackward1>) tensor([0.8411, 0.1082, 0.0507], grad_fn=<MeanBackward1>) tensor(18.7812, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.859375 tensor([9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 8., 8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -8.802120208740234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/200][610/2079]\tG Loss: -0.3673;D Loss: -0.5817; GP: 0.1421\n",
      "now, we train G 2 times with (prob fake = 0.367, prob real = 0.967)\n",
      "Mean x/edge attr:  tensor([0.7331, 0.1085, 0.1584, 0.0000, 0.9715, 0.0196, 0.0089, 0.7936, 0.0641,\n",
      "        0.1423], grad_fn=<MeanBackward1>) tensor([0.8703, 0.0870, 0.0427], grad_fn=<MeanBackward1>) tensor(18.3125, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.78125 tensor([9., 9., 8., 9., 9., 8., 9., 9., 9., 8., 9., 9., 9., 9., 8., 8., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 8., 8., 9., 8., 9., 9., 9., 9., 9., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 8.,\n",
      "        9., 8., 9., 9., 9., 9., 9., 9., 9., 8.])\n",
      "Sample prob: -8.463835716247559\n",
      "Validation, uniqueness, novelty:  (0.732, 0.7923497267759563, 0.9431034482758621)\n",
      "[6/200][710/2079]\tG Loss: -0.4370;D Loss: -0.3454; GP: 0.0916\n",
      "now, we train G 2 times with (prob fake = 0.437, prob real = 0.746)\n",
      "Mean x/edge attr:  tensor([0.7196, 0.1182, 0.1570, 0.0053, 0.9788, 0.0088, 0.0123, 0.7848, 0.0811,\n",
      "        0.1340], grad_fn=<MeanBackward1>) tensor([0.8663, 0.1106, 0.0231], grad_fn=<MeanBackward1>) tensor(18.9375, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.859375 tensor([9., 9., 9., 9., 8., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 8., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 9., 8., 9., 9., 9.])\n",
      "Sample prob: -8.078192710876465\n",
      "[6/200][810/2079]\tG Loss: -0.1419;D Loss: -0.5689; GP: 0.0864\n",
      "now, we train G 2 times with (prob fake = 0.142, prob real = 0.763)\n",
      "Mean x/edge attr:  tensor([0.7016, 0.1134, 0.1832, 0.0017, 0.9703, 0.0244, 0.0052, 0.8028, 0.0681,\n",
      "        0.1291], grad_fn=<MeanBackward1>) tensor([0.8608, 0.1025, 0.0367], grad_fn=<MeanBackward1>) tensor(18.7500, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.953125 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 8.])\n",
      "Sample prob: -8.750263214111328\n",
      "Validation, uniqueness, novelty:  (0.859, 0.7881257275902211, 0.9453471196454948)\n",
      "[6/200][910/2079]\tG Loss: -0.0032;D Loss: -0.5859; GP: 0.1356\n",
      "now, we train G 2 times with (prob fake = 0.003, prob real = 0.635)\n",
      "Mean x/edge attr:  tensor([0.7287, 0.0957, 0.1720, 0.0035, 0.9752, 0.0248, 0.0000, 0.7979, 0.0603,\n",
      "        0.1418], grad_fn=<MeanBackward1>) tensor([0.8678, 0.1027, 0.0295], grad_fn=<MeanBackward1>) tensor(18.5625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.8125 tensor([9., 8., 8., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 9., 8., 9., 9., 9., 9., 8., 8., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 8., 9.,\n",
      "        9., 8., 9., 9., 9., 9., 9., 8., 8., 9.])\n",
      "Sample prob: -9.15273666381836\n",
      "[6/200][1010/2079]\tG Loss: 0.1163;D Loss: -0.5827; GP: 0.0993\n",
      "now, we train G 2 times with (prob fake = -0.116, prob real = 0.415)\n",
      "Mean x/edge attr:  tensor([0.7335, 0.1055, 0.1610, 0.0000, 0.9499, 0.0429, 0.0072, 0.7227, 0.0930,\n",
      "        0.1843], grad_fn=<MeanBackward1>) tensor([0.8926, 0.0810, 0.0264], grad_fn=<MeanBackward1>) tensor(18.9062, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.734375 tensor([9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 9., 8., 9., 8., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        9., 8., 8., 9., 8., 8., 8., 9., 9., 8., 9., 9., 8., 8., 9., 8., 9., 9.,\n",
      "        9., 8., 8., 8., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -9.107148170471191\n",
      "Validation, uniqueness, novelty:  (0.715, 0.6853146853146853, 0.936734693877551)\n",
      "[6/200][1110/2079]\tG Loss: -0.3518;D Loss: -0.2394; GP: 0.1091\n",
      "now, we train G 2 times with (prob fake = 0.352, prob real = 0.555)\n",
      "Mean x/edge attr:  tensor([0.7568, 0.1009, 0.1423, 0.0000, 0.9730, 0.0252, 0.0018, 0.7532, 0.0865,\n",
      "        0.1604], grad_fn=<MeanBackward1>) tensor([0.9058, 0.0603, 0.0339], grad_fn=<MeanBackward1>) tensor(18.9062, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.671875 tensor([9., 9., 7., 8., 9., 9., 9., 9., 9., 8., 8., 8., 9., 8., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 8., 8., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 8., 8., 9., 9., 8., 9., 9., 8., 9., 9., 9.,\n",
      "        8., 9., 9., 7., 9., 9., 8., 8., 9., 9.])\n",
      "Sample prob: -8.0301513671875\n",
      "[6/200][1210/2079]\tG Loss: -0.1799;D Loss: -0.2724; GP: 0.0926\n",
      "now, we train G 2 times with (prob fake = 0.180, prob real = 0.402)\n",
      "Mean x/edge attr:  tensor([0.7603, 0.0930, 0.1467, 0.0000, 0.9660, 0.0322, 0.0018, 0.7120, 0.0805,\n",
      "        0.2075], grad_fn=<MeanBackward1>) tensor([0.9082, 0.0692, 0.0225], grad_fn=<MeanBackward1>) tensor(19.4062, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.734375 tensor([9., 9., 9., 9., 9., 8., 8., 9., 9., 9., 9., 9., 8., 8., 9., 9., 8., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 8.,\n",
      "        8., 9., 9., 9., 9., 9., 9., 8., 9., 9., 8., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        8., 8., 8., 8., 8., 9., 9., 9., 9., 8.])\n",
      "Sample prob: -7.880168914794922\n",
      "Validation, uniqueness, novelty:  (0.829, 0.6731001206272618, 0.9139784946236559)\n",
      "[6/200][1310/2079]\tG Loss: 0.0109;D Loss: -0.5798; GP: 0.0888\n",
      "now, we train G 2 times with (prob fake = -0.011, prob real = 0.590)\n",
      "Mean x/edge attr:  tensor([0.7054, 0.1518, 0.1393, 0.0036, 0.9625, 0.0232, 0.0143, 0.7714, 0.0589,\n",
      "        0.1696], grad_fn=<MeanBackward1>) tensor([0.8941, 0.0689, 0.0370], grad_fn=<MeanBackward1>) tensor(18.5938, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.75 tensor([9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 8., 9., 8., 9., 9., 9., 8., 8.,\n",
      "        9., 8., 9., 8., 9., 9., 9., 9., 8., 9., 9., 8., 9., 8., 9., 8., 9., 8.,\n",
      "        9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 9., 9., 9., 8., 8., 9., 9., 9.])\n",
      "Sample prob: -7.81407356262207\n",
      "[6/200][1410/2079]\tG Loss: -0.1760;D Loss: -0.6321; GP: 0.1012\n",
      "now, we train G 2 times with (prob fake = 0.176, prob real = 0.802)\n",
      "Mean x/edge attr:  tensor([0.7052, 0.1013, 0.1935, 0.0000, 0.9855, 0.0090, 0.0054, 0.7848, 0.0832,\n",
      "        0.1320], grad_fn=<MeanBackward1>) tensor([0.8643, 0.1107, 0.0250], grad_fn=<MeanBackward1>) tensor(17.5000, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.640625 tensor([9., 8., 9., 9., 9., 8., 8., 9., 8., 9., 9., 9., 9., 9., 9., 8., 8., 8.,\n",
      "        9., 9., 9., 8., 8., 9., 9., 8., 9., 9., 9., 9., 8., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 9., 8., 9., 8., 9., 9., 8., 9., 8., 9., 9., 9., 9., 8., 8., 8.,\n",
      "        9., 9., 9., 8., 9., 8., 8., 9., 8., 9.])\n",
      "Sample prob: -7.640427589416504\n",
      "Validation, uniqueness, novelty:  (0.658, 0.776595744680851, 0.9080234833659491)\n",
      "[6/200][1510/2079]\tG Loss: 0.0129;D Loss: -0.4843; GP: 0.1067\n",
      "now, we train G 2 times with (prob fake = -0.013, prob real = 0.430)\n",
      "Mean x/edge attr:  tensor([0.6887, 0.1449, 0.1628, 0.0036, 0.9410, 0.0465, 0.0125, 0.8354, 0.0626,\n",
      "        0.1020], grad_fn=<MeanBackward1>) tensor([0.8590, 0.1000, 0.0410], grad_fn=<MeanBackward1>) tensor(18.2812, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.734375 tensor([9., 8., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 8., 8., 9.,\n",
      "        9., 8., 9., 9., 9., 9., 8., 9., 9., 8., 9., 9., 9., 9., 9., 8., 8., 8.,\n",
      "        9., 8., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 8., 8., 9., 8., 9., 8., 9., 9., 9.])\n",
      "Sample prob: -6.154562473297119\n",
      "[6/200][1610/2079]\tG Loss: -0.0513;D Loss: -0.5746; GP: 0.0805\n",
      "now, we train G 2 times with (prob fake = 0.051, prob real = 0.615)\n",
      "Mean x/edge attr:  tensor([0.6938, 0.1250, 0.1757, 0.0054, 0.9801, 0.0145, 0.0054, 0.7808, 0.0326,\n",
      "        0.1866], grad_fn=<MeanBackward1>) tensor([0.8586, 0.1143, 0.0271], grad_fn=<MeanBackward1>) tensor(17.9062, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.625 tensor([8., 9., 8., 9., 9., 9., 9., 8., 9., 8., 9., 9., 8., 8., 9., 8., 9., 9.,\n",
      "        9., 8., 8., 9., 8., 9., 9., 8., 9., 9., 9., 8., 8., 8., 9., 9., 8., 8.,\n",
      "        9., 9., 8., 8., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 8., 8., 9., 9.,\n",
      "        9., 8., 8., 8., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -6.276458740234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation, uniqueness, novelty:  (0.774, 0.6188630490956072, 0.9144050104384134)\n",
      "[6/200][1710/2079]\tG Loss: 0.0552;D Loss: -0.8260; GP: 0.7924\n",
      "now, we train G 2 times with (prob fake = -0.055, prob real = 0.517)\n",
      "Mean x/edge attr:  tensor([0.7891, 0.0861, 0.1248, 0.0000, 0.9543, 0.0351, 0.0105, 0.7926, 0.0633,\n",
      "        0.1441], grad_fn=<MeanBackward1>) tensor([0.8926, 0.0930, 0.0144], grad_fn=<MeanBackward1>) tensor(17.3125, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.890625 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 8., 9.,\n",
      "        9., 9., 8., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 8., 9., 9.])\n",
      "Sample prob: -6.333161354064941\n",
      "[6/200][1810/2079]\tG Loss: 0.5022;D Loss: -1.1680; GP: 0.4951\n",
      "now, we train G 2 times with (prob fake = -0.502, prob real = 0.642)\n",
      "Mean x/edge attr:  tensor([0.7703, 0.0777, 0.1519, 0.0000, 0.9841, 0.0053, 0.0106, 0.7597, 0.1078,\n",
      "        0.1325], grad_fn=<MeanBackward1>) tensor([0.9091, 0.0694, 0.0215], grad_fn=<MeanBackward1>) tensor(19.5938, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.84375 tensor([9., 9., 9., 8., 8., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 9., 8., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 9., 9., 9., 9., 7.])\n",
      "Sample prob: -4.844480991363525\n",
      "Validation, uniqueness, novelty:  (0.15, 0.38666666666666666, 0.9137931034482759)\n",
      "[6/200][1910/2079]\tG Loss: 0.5085;D Loss: -1.2122; GP: 0.5005\n",
      "now, we train G 2 times with (prob fake = -0.508, prob real = 0.810)\n",
      "Mean x/edge attr:  tensor([0.8579, 0.0175, 0.1228, 0.0018, 1.0000, 0.0000, 0.0000, 0.7105, 0.0877,\n",
      "        0.2018], grad_fn=<MeanBackward1>) tensor([0.8656, 0.1164, 0.0180], grad_fn=<MeanBackward1>) tensor(19.0625, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.90625 tensor([9., 9., 8., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 8., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.137215614318848\n",
      "[6/200][2010/2079]\tG Loss: 0.9513;D Loss: -1.1525; GP: 0.2811\n",
      "now, we train G 2 times with (prob fake = -0.951, prob real = 0.326)\n",
      "Mean x/edge attr:  tensor([0.7739, 0.1357, 0.0870, 0.0035, 1.0000, 0.0000, 0.0000, 0.8417, 0.0730,\n",
      "        0.0852], grad_fn=<MeanBackward1>) tensor([0.8393, 0.0923, 0.0684], grad_fn=<MeanBackward1>) tensor(18.2812, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.984375 tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -6.331456184387207\n",
      "Validation, uniqueness, novelty:  (0.078, 0.3333333333333333, 0.6923076923076923)\n",
      "less than 64\n",
      "[7/200][32/2079]\tG Loss: 0.5432;D Loss: -1.2876; GP: 0.2338\n",
      "now, we train G 2 times with (prob fake = -0.543, prob real = 0.746)\n",
      "Mean x/edge attr:  tensor([0.7238, 0.1516, 0.1245, 0.0000, 0.9874, 0.0126, 0.0000, 0.7708, 0.0704,\n",
      "        0.1588], grad_fn=<MeanBackward1>) tensor([0.8601, 0.1093, 0.0306], grad_fn=<MeanBackward1>) tensor(17.8750, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.65625 tensor([9., 9., 8., 8., 8., 9., 9., 9., 8., 8., 9., 9., 8., 9., 9., 9., 9., 8.,\n",
      "        8., 9., 8., 9., 8., 9., 8., 9., 9., 9., 9., 8., 9., 8., 9., 9., 8., 8.,\n",
      "        9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 8.,\n",
      "        9., 9., 9., 8., 9., 8., 8., 8., 9., 9.])\n",
      "Sample prob: -6.126089096069336\n",
      "[7/200][132/2079]\tG Loss: 0.3917;D Loss: -1.2806; GP: 0.2379\n",
      "now, we train G 2 times with (prob fake = -0.392, prob real = 0.945)\n",
      "Mean x/edge attr:  tensor([0.7770, 0.0719, 0.1511, 0.0000, 1.0000, 0.0000, 0.0000, 0.7428, 0.1259,\n",
      "        0.1313], grad_fn=<MeanBackward1>) tensor([0.8950, 0.0879, 0.0171], grad_fn=<MeanBackward1>) tensor(19.1875, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.6875 tensor([9., 8., 8., 8., 8., 9., 9., 9., 9., 8., 8., 9., 8., 9., 9., 8., 8., 9.,\n",
      "        9., 9., 8., 9., 8., 9., 9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        8., 9., 8., 9., 9., 9., 9., 8., 9., 9., 8., 9., 9., 8., 9., 9., 9., 8.,\n",
      "        8., 8., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -5.456189155578613\n",
      "Validation, uniqueness, novelty:  (0.013, 0.6923076923076923, 1.0)\n",
      "[7/200][232/2079]\tG Loss: 0.1952;D Loss: -1.3292; GP: 0.5622\n",
      "now, we train G 2 times with (prob fake = -0.195, prob real = 1.044)\n",
      "Mean x/edge attr:  tensor([0.7856, 0.0791, 0.1353, 0.0000, 0.8629, 0.1336, 0.0035, 0.7135, 0.1213,\n",
      "        0.1652], grad_fn=<MeanBackward1>) tensor([0.9005, 0.0390, 0.0605], grad_fn=<MeanBackward1>) tensor(19.6250, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.890625 tensor([9., 8., 9., 9., 8., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 8., 9., 9., 9., 9., 9., 9., 8., 9., 8., 9., 9., 9.,\n",
      "        9., 8., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "        9., 9., 9., 9., 9., 9., 9., 9., 9., 9.])\n",
      "Sample prob: -4.672979354858398\n",
      "[7/200][332/2079]\tG Loss: -0.5667;D Loss: -0.5470; GP: 1.7831\n",
      "now, we train G 2 times with (prob fake = 0.567, prob real = 1.078)\n",
      "Mean x/edge attr:  tensor([0.8105, 0.0056, 0.1839, 0.0000, 1.0000, 0.0000, 0.0000, 0.7261, 0.1614,\n",
      "        0.1126], grad_fn=<MeanBackward1>) tensor([0.9610, 0.0172, 0.0218], grad_fn=<MeanBackward1>) tensor(20.0312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.328125 tensor([8., 8., 8., 8., 9., 8., 8., 9., 9., 9., 9., 8., 9., 8., 8., 8., 8., 9.,\n",
      "        9., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 9., 8., 9., 9., 9.,\n",
      "        8., 9., 9., 9., 8., 8., 8., 8., 8., 9., 8., 9., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 9., 8., 9., 9., 8., 8., 9., 8.])\n",
      "Sample prob: -6.714223384857178\n",
      "Validation, uniqueness, novelty:  (0.085, 0.4588235294117647, 0.9743589743589743)\n",
      "[7/200][432/2079]\tG Loss: 0.1290;D Loss: -0.9213; GP: 0.3373\n",
      "now, we train G 2 times with (prob fake = -0.129, prob real = 0.730)\n",
      "Mean x/edge attr:  tensor([0.8346, 0.0320, 0.1335, 0.0000, 0.9906, 0.0019, 0.0075, 0.8346, 0.0338,\n",
      "        0.1316], grad_fn=<MeanBackward1>) tensor([0.8540, 0.1044, 0.0416], grad_fn=<MeanBackward1>) tensor(16.9062, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.3125 tensor([8., 8., 8., 8., 9., 8., 9., 8., 8., 8., 8., 8., 9., 9., 6., 8., 8., 9.,\n",
      "        8., 8., 8., 8., 8., 8., 9., 9., 8., 8., 8., 8., 9., 9., 8., 9., 8., 8.,\n",
      "        9., 8., 8., 8., 8., 9., 8., 8., 8., 8., 8., 9., 9., 8., 9., 9., 9., 9.,\n",
      "        8., 9., 8., 9., 8., 8., 9., 9., 8., 8.])\n",
      "Sample prob: -6.622583389282227\n",
      "[7/200][532/2079]\tG Loss: 0.3978;D Loss: -1.5420; GP: 0.1973\n",
      "now, we train G 2 times with (prob fake = -0.398, prob real = 1.142)\n",
      "Mean x/edge attr:  tensor([0.7286, 0.1097, 0.1617, 0.0000, 0.9926, 0.0074, 0.0000, 0.7937, 0.0669,\n",
      "        0.1394], grad_fn=<MeanBackward1>) tensor([0.8312, 0.1239, 0.0450], grad_fn=<MeanBackward1>) tensor(17.0312, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.40625 tensor([9., 8., 8., 8., 8., 9., 8., 8., 9., 8., 8., 9., 8., 8., 9., 9., 8., 8.,\n",
      "        9., 8., 9., 8., 8., 8., 8., 9., 9., 8., 8., 8., 8., 8., 8., 8., 9., 9.,\n",
      "        9., 9., 8., 8., 8., 9., 9., 9., 8., 8., 9., 8., 9., 8., 8., 9., 9., 9.,\n",
      "        8., 9., 8., 8., 8., 8., 9., 8., 9., 9.])\n",
      "Sample prob: -6.922269821166992\n",
      "Validation, uniqueness, novelty:  (0.045, 0.8, 0.9444444444444444)\n",
      "[7/200][632/2079]\tG Loss: 0.5974;D Loss: -1.4895; GP: 0.2352\n",
      "now, we train G 2 times with (prob fake = -0.597, prob real = 1.034)\n",
      "Mean x/edge attr:  tensor([0.6800, 0.1619, 0.1581, 0.0000, 0.9314, 0.0286, 0.0400, 0.7410, 0.0781,\n",
      "        0.1810], grad_fn=<MeanBackward1>) tensor([0.8933, 0.0820, 0.0247], grad_fn=<MeanBackward1>) tensor(17.7188, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.203125 tensor([8., 8., 8., 8., 8., 8., 9., 8., 9., 9., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        9., 8., 6., 8., 8., 9., 9., 8., 8., 9., 8., 8., 8., 9., 9., 8., 9., 9.,\n",
      "        8., 8., 9., 8., 8., 8., 8., 8., 8., 8., 9., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        9., 8., 8., 8., 8., 8., 8., 9., 8., 8.])\n",
      "Sample prob: -6.904862880706787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/200][732/2079]\tG Loss: 0.5731;D Loss: -1.4626; GP: 0.5709\n",
      "now, we train G 2 times with (prob fake = -0.573, prob real = 0.975)\n",
      "Mean x/edge attr:  tensor([0.7466, 0.1306, 0.0000, 0.1228, 0.8772, 0.1228, 0.0000, 0.8694, 0.0097,\n",
      "        0.1209], grad_fn=<MeanBackward1>) tensor([0.8503, 0.0133, 0.1364], grad_fn=<MeanBackward1>) tensor(14.0938, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.015625 tensor([8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 9., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 8., 8.])\n",
      "Sample prob: -1.1035795211791992\n",
      "Validation, uniqueness, novelty:  (0.0, 0, 0)\n",
      "[7/200][832/2079]\tG Loss: -0.0116;D Loss: -1.4513; GP: 0.2438\n",
      "now, we train G 2 times with (prob fake = 0.012, prob real = 1.403)\n",
      "Mean x/edge attr:  tensor([0.8116, 0.0429, 0.1455, 0.0000, 0.9683, 0.0168, 0.0149, 0.7146, 0.0653,\n",
      "        0.2201], grad_fn=<MeanBackward1>) tensor([9.2961e-01, 6.9579e-02, 8.0906e-04], grad_fn=<MeanBackward1>) tensor(19.3125, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.375 tensor([9., 9., 9., 8., 8., 8., 8., 9., 8., 8., 9., 8., 8., 8., 9., 8., 9., 8.,\n",
      "        8., 8., 9., 9., 9., 9., 8., 8., 8., 8., 9., 8., 8., 8., 9., 9., 8., 9.,\n",
      "        8., 9., 9., 8., 8., 9., 8., 8., 9., 8., 9., 8., 8., 8., 9., 9., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 9., 9., 8., 8.])\n",
      "Sample prob: -6.474569320678711\n",
      "[7/200][932/2079]\tG Loss: 0.3869;D Loss: -1.5521; GP: 0.0915\n",
      "now, we train G 2 times with (prob fake = -0.387, prob real = 1.228)\n",
      "Mean x/edge attr:  tensor([0.7524, 0.0705, 0.1771, 0.0000, 0.9867, 0.0133, 0.0000, 0.7676, 0.1086,\n",
      "        0.1238], grad_fn=<MeanBackward1>) tensor([0.8611, 0.1106, 0.0283], grad_fn=<MeanBackward1>) tensor(17.6562, grad_fn=<DivBackward0>)\n",
      "size x/ some distribution: 8.203125 tensor([8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 9., 8., 8., 9., 9., 8., 8., 8.,\n",
      "        8., 9., 8., 8., 8., 8., 8., 8., 8., 9., 8., 8., 8., 8., 8., 8., 8., 9.,\n",
      "        8., 8., 9., 8., 9., 8., 9., 8., 8., 9., 8., 8., 9., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 9., 8., 9., 8., 8., 8., 8., 8.])\n",
      "Sample prob: -5.400033473968506\n",
      "Validation, uniqueness, novelty:  (0.012, 1.0, 0.9166666666666666)\n"
     ]
    }
   ],
   "source": [
    "train.train(data_loader, verbose=False, use_data_x = 10, use_data_edgeattr=3, \\\n",
    "        evaluate_num=1000, mol_data=mol_data, alter_trainer=True, NN=200, reinforce_acclerate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "candidate_evals = [(i,j ) for i,j in enumerate(train.evals) if j[0] > 0.9]\n",
    "candidate_metrics = [np.prod(j) for i,j in enumerate(train.evals) if j[0] > 0.9]\n",
    "choose_model = candidate_evals[np.argmax(candidate_metrics)][0]\n",
    "generator = torch.load(os.path.join(train.folder, f'generator_{choose_model}.pt'))\n",
    "torch.save(generator, 'ul_gan_qm9.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
